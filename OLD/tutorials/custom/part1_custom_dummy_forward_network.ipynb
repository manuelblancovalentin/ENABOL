{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to create a simple forward-only network using hls4ml. We will exlore later what we need to change to turn it into a network that has the ability to perform backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 17:34:02.264860: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/4.9.3/:/fpga/cad/intel/intelFPGA_lite/20.1/hls/host/linux64/lib:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/4.9.3/:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/4.9.3/:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/4.9.3/:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/4.9.3/:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/4.9.3/:\n",
      "2023-01-24 17:34:02.264881: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "os.environ['PATH'] = '/fpga/cad/xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "os.environ['LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu:/usr/lib32:'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load a very dummy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds_dir = \"../../datasets/dummy_linear_half\"\n",
    "\n",
    "load = lambda x: np.load(os.path.join(ds_dir,x))\n",
    "X_train_val = load('X_train_val.npy')\n",
    "X_test = load('X_test.npy')\n",
    "y_train_val = load('y_train_val.npy')\n",
    "y_test = load('y_test.npy')\n",
    "#classes = np.load('classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a model\n",
    "This time we're going to use QKeras layers.\n",
    "QKeras is \"Quantized Keras\" for deep heterogeneous quantization of ML models.\n",
    "\n",
    "https://github.com/google/qkeras\n",
    "\n",
    "It is maintained by Google and we recently added support for QKeras model to hls4ml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "from tensorflow.keras.layers import Activation\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using `QDense` layer instead of `Dense`, and `QActivation` instead of `Activation`. We're also specifying `kernel_quantizer = quantized_bits(6,0,0)`. This will use 6-bits (of which 0 are integer) for the weights. We also use the same quantization for the biases, and `quantized_relu(6)` for 6-bit ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = Sequential()\n",
    "model.add(QDense(1, input_shape=(1,), \n",
    "                name='fc1',\n",
    "                kernel_quantizer=quantized_bits(6,0,alpha=1), \n",
    "                bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', \n",
    "                kernel_regularizer=l1(0.0001),\n",
    "                use_bias = False))\n",
    "# model.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
    "# model.add(QDense(32, name='fc2',\n",
    "#                  kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "#                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "# model.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
    "# model.add(QDense(32, name='fc3',\n",
    "#                  kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "#                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "# model.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
    "# model.add(QDense(5, name='output',\n",
    "#                  kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "#                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train sparse\n",
    "Let's train with model sparsity again, since QKeras layers are prunable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.\n",
    "The callbacks will decay the learning rate and save the model into a directory 'model_2'\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU.\n",
    "If you've restarted the notebook kernel after training once, set `train = False` to load the trained model rather than training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 17:40:10.192744: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2023-01-24 17:40:10.192768: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2023-01-24 17:40:10.192817: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/375 [..............................] - ETA: 2:14 - loss: 0.0915 - mse: 0.0914WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0073s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 17:40:10.591773: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2023-01-24 17:40:10.591795: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2023-01-24 17:40:10.620199: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2023-01-24 17:40:10.620804: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2023-01-24 17:40:10.621850: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10\n",
      "2023-01-24 17:40:10.622435: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.trace.json.gz\n",
      "2023-01-24 17:40:10.623331: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10\n",
      "2023-01-24 17:40:10.623399: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.memory_profile.json.gz\n",
      "2023-01-24 17:40:10.623559: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10Dumped tool data for xplane.pb to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.xplane.pb\n",
      "Dumped tool data for overview_page.pb to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to model_dummy_forward/logs/train/plugins/profile/2023_01_24_17_40_10/kona-ubuntu.kernel_stats.pb\n",
      "\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0073s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 4.8632e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00001: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00001: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 0s 629us/step - loss: 7.1133e-05 - mse: 2.1362e-05 - val_loss: 4.9578e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00002: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00002: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 0s 638us/step - loss: 6.1526e-05 - mse: 1.1974e-05 - val_loss: 5.0358e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00003: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00003: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 0s 611us/step - loss: 5.8247e-05 - mse: 8.5300e-06 - val_loss: 5.1270e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00004: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00004: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 0s 607us/step - loss: 8.3596e-05 - mse: 3.3618e-05 - val_loss: 5.0169e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00005: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00005: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 0s 613us/step - loss: 8.5065e-05 - mse: 3.5033e-05 - val_loss: 5.1139e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00006: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00006: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 0s 622us/step - loss: 5.4751e-05 - mse: 4.3585e-06 - val_loss: 4.9857e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00007: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00007: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 0s 612us/step - loss: 5.8473e-05 - mse: 8.7460e-06 - val_loss: 5.1007e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00008: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00008: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 0s 648us/step - loss: 5.7000e-05 - mse: 6.7743e-06 - val_loss: 5.0947e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00009: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00009: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 0s 621us/step - loss: 6.5001e-05 - mse: 1.4943e-05 - val_loss: 4.9590e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00010: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00010: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to model_dummy_forward/KERAS_check_model_epoch10.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 0s 637us/step - loss: 5.7922e-05 - mse: 8.0302e-06 - val_loss: 4.8875e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00011: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00011: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 0s 648us/step - loss: 5.4509e-05 - mse: 5.2163e-06 - val_loss: 5.0339e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00012: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00012: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 0s 631us/step - loss: 5.8879e-05 - mse: 8.7235e-06 - val_loss: 4.8483e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00013: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00013: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 0s 656us/step - loss: 6.2581e-05 - mse: 1.2683e-05 - val_loss: 5.0388e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00014: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00014: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 0s 626us/step - loss: 5.0653e-05 - mse: 1.0610e-06 - val_loss: 4.9415e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00015: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00015: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 0s 616us/step - loss: 5.4719e-05 - mse: 5.2722e-06 - val_loss: 4.9122e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00016: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00016: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 0s 619us/step - loss: 5.2895e-05 - mse: 3.0591e-06 - val_loss: 4.9302e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00017: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00017: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 0s 615us/step - loss: 5.2829e-05 - mse: 2.9895e-06 - val_loss: 4.8706e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00018: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00018: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 0s 630us/step - loss: 5.1344e-05 - mse: 2.2522e-06 - val_loss: 5.0219e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00019: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00019: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 0s 609us/step - loss: 5.0325e-05 - mse: 7.9103e-07 - val_loss: 4.9386e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00020: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00020: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to model_dummy_forward/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 0s 610us/step - loss: 5.1026e-05 - mse: 1.6173e-06 - val_loss: 4.8942e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00021: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00021: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 0s 642us/step - loss: 5.1947e-05 - mse: 2.3351e-06 - val_loss: 4.8804e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00022: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00022: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 0s 639us/step - loss: 5.1431e-05 - mse: 2.2750e-06 - val_loss: 4.8761e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00023: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00023: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 0s 621us/step - loss: 5.1796e-05 - mse: 2.5529e-06 - val_loss: 4.9115e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00024: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00024: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 0s 638us/step - loss: 5.1180e-05 - mse: 1.9312e-06 - val_loss: 5.0159e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00025: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00025: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 0s 611us/step - loss: 5.0209e-05 - mse: 6.4318e-07 - val_loss: 4.8515e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00026: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00026: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 0s 617us/step - loss: 5.2749e-05 - mse: 3.7442e-06 - val_loss: 4.8950e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00027: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00027: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 0s 656us/step - loss: 4.9890e-05 - mse: 1.1055e-06 - val_loss: 4.8629e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00028: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00028: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 0s 626us/step - loss: 5.0806e-05 - mse: 2.0725e-06 - val_loss: 4.9648e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00029: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00029: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 0s 627us/step - loss: 4.9764e-05 - mse: 4.8946e-07 - val_loss: 4.9086e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00030: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00030: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00030: saving model to model_dummy_forward/KERAS_check_model_epoch30.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 0s 637us/step - loss: 4.9185e-05 - mse: 3.1062e-07 - val_loss: 4.8584e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00031: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00031: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 0s 617us/step - loss: 5.0957e-05 - mse: 2.2718e-06 - val_loss: 4.8675e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00032: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00032: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 0s 627us/step - loss: 5.0025e-05 - mse: 1.3902e-06 - val_loss: 4.8608e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00033: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00033: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 0s 645us/step - loss: 5.0885e-05 - mse: 2.1916e-06 - val_loss: 4.8820e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00034: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00034: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 0s 620us/step - loss: 4.8972e-05 - mse: 2.6680e-07 - val_loss: 4.8604e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00035: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00035: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 0s 636us/step - loss: 5.0039e-05 - mse: 1.4562e-06 - val_loss: 4.8480e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00036: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00036: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 0s 624us/step - loss: 5.1370e-05 - mse: 2.8099e-06 - val_loss: 4.8586e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00037: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00037: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 0s 624us/step - loss: 4.9722e-05 - mse: 1.1792e-06 - val_loss: 4.8642e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00038: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00038: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.765625145519152e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 0s 629us/step - loss: 4.8698e-05 - mse: 1.1550e-07 - val_loss: 4.8484e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00039: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00039: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 0s 624us/step - loss: 5.0558e-05 - mse: 2.0570e-06 - val_loss: 4.8507e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00040: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00040: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00040: saving model to model_dummy_forward/KERAS_check_model_epoch40.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 0s 610us/step - loss: 4.9777e-05 - mse: 1.2869e-06 - val_loss: 4.8518e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00041: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00041: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 0s 611us/step - loss: 4.9486e-05 - mse: 9.9860e-07 - val_loss: 4.8485e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00042: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00042: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 4.882812572759576e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 0s 603us/step - loss: 4.9487e-05 - mse: 1.0170e-06 - val_loss: 4.8486e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00043: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00043: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 0s 607us/step - loss: 4.9535e-05 - mse: 1.0620e-06 - val_loss: 4.8441e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00044: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00044: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 0s 614us/step - loss: 5.3007e-05 - mse: 4.5247e-06 - val_loss: 4.8445e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00045: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00045: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 0s 608us/step - loss: 5.0743e-05 - mse: 2.2881e-06 - val_loss: 4.8477e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00046: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00046: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.441406286379788e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 0s 605us/step - loss: 4.9071e-05 - mse: 6.0648e-07 - val_loss: 4.8458e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00047: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00047: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 0s 642us/step - loss: 4.9537e-05 - mse: 1.0859e-06 - val_loss: 4.8455e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00048: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00048: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 0s 616us/step - loss: 4.9732e-05 - mse: 1.2810e-06 - val_loss: 4.8461e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00049: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00049: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 0s 608us/step - loss: 4.9377e-05 - mse: 9.2384e-07 - val_loss: 4.8463e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00050: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00050: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00050: saving model to model_dummy_forward/KERAS_check_model_epoch50.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.220703143189894e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 0s 597us/step - loss: 4.8699e-05 - mse: 2.4377e-07 - val_loss: 4.8450e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00051: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00051: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 0s 622us/step - loss: 4.9760e-05 - mse: 1.3121e-06 - val_loss: 4.8444e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00052: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00052: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 0s 615us/step - loss: 5.0160e-05 - mse: 1.7154e-06 - val_loss: 4.8449e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00053: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00053: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 54/80\n",
      "375/375 [==============================] - 0s 614us/step - loss: 4.9398e-05 - mse: 9.5205e-07 - val_loss: 4.8446e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00054: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00054: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 55/80\n",
      "375/375 [==============================] - 0s 618us/step - loss: 4.8799e-05 - mse: 3.5106e-07 - val_loss: 4.8443e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00055: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00055: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 56/80\n",
      "375/375 [==============================] - 0s 616us/step - loss: 5.0069e-05 - mse: 1.6265e-06 - val_loss: 4.8445e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00056: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00056: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 57/80\n",
      "375/375 [==============================] - 0s 609us/step - loss: 4.9729e-05 - mse: 1.2859e-06 - val_loss: 4.8450e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00057: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00057: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 58/80\n",
      "375/375 [==============================] - 0s 617us/step - loss: 4.9347e-05 - mse: 9.0107e-07 - val_loss: 4.8445e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00058: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00058: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 59/80\n",
      "375/375 [==============================] - 0s 617us/step - loss: 4.9440e-05 - mse: 9.9844e-07 - val_loss: 4.8440e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00059: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00059: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 60/80\n",
      "375/375 [==============================] - 0s 628us/step - loss: 5.0548e-05 - mse: 2.1066e-06 - val_loss: 4.8443e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00060: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00060: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00060: saving model to model_dummy_forward/KERAS_check_model_epoch60.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 61/80\n",
      "375/375 [==============================] - 0s 634us/step - loss: 4.8785e-05 - mse: 3.3926e-07 - val_loss: 4.8438e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00005 to 0.00005, saving model to model_dummy_forward/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00061: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00061: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 62/80\n",
      "375/375 [==============================] - 0s 632us/step - loss: 5.4117e-05 - mse: 5.6695e-06 - val_loss: 4.8447e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00062: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00062: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 63/80\n",
      "375/375 [==============================] - 0s 619us/step - loss: 4.9493e-05 - mse: 1.0484e-06 - val_loss: 4.8441e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00063: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00063: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 64/80\n",
      "375/375 [==============================] - 0s 608us/step - loss: 5.0800e-05 - mse: 2.3563e-06 - val_loss: 4.8444e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00064: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00064: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 65/80\n",
      "375/375 [==============================] - 0s 639us/step - loss: 5.0028e-05 - mse: 1.5847e-06 - val_loss: 4.8446e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00065: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00065: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 66/80\n",
      "375/375 [==============================] - 0s 619us/step - loss: 4.9311e-05 - mse: 8.6761e-07 - val_loss: 4.8444e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00066: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00066: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 67/80\n",
      "375/375 [==============================] - 0s 622us/step - loss: 4.9748e-05 - mse: 1.3058e-06 - val_loss: 4.8446e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00067: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00067: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 68/80\n",
      "375/375 [==============================] - 0s 628us/step - loss: 4.9877e-05 - mse: 1.4323e-06 - val_loss: 4.8439e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00068: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00068: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 69/80\n",
      "375/375 [==============================] - 0s 612us/step - loss: 5.1789e-05 - mse: 3.3445e-06 - val_loss: 4.8444e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00069: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00069: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 70/80\n",
      "375/375 [==============================] - 0s 627us/step - loss: 4.9674e-05 - mse: 1.2313e-06 - val_loss: 4.8443e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00070: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00070: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00070: saving model to model_dummy_forward/KERAS_check_model_epoch70.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 71/80\n",
      "375/375 [==============================] - 0s 645us/step - loss: 4.9991e-05 - mse: 1.5487e-06 - val_loss: 4.8443e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00071: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00071: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 72/80\n",
      "375/375 [==============================] - 0s 627us/step - loss: 4.9846e-05 - mse: 1.4039e-06 - val_loss: 4.8442e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00072: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00072: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 73/80\n",
      "375/375 [==============================] - 0s 615us/step - loss: 5.0175e-05 - mse: 1.7326e-06 - val_loss: 4.8442e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00073: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00073: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 74/80\n",
      "375/375 [==============================] - 0s 620us/step - loss: 4.9983e-05 - mse: 1.5408e-06 - val_loss: 4.8439e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00074: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00074: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 75/80\n",
      "375/375 [==============================] - 0s 625us/step - loss: 5.1353e-05 - mse: 2.9092e-06 - val_loss: 4.8440e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00075: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00075: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 76/80\n",
      "375/375 [==============================] - 0s 621us/step - loss: 5.0854e-05 - mse: 2.4111e-06 - val_loss: 4.8445e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00076: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00076: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 77/80\n",
      "375/375 [==============================] - 0s 614us/step - loss: 4.9712e-05 - mse: 1.2688e-06 - val_loss: 4.8444e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00077: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00077: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 78/80\n",
      "375/375 [==============================] - 0s 615us/step - loss: 4.9985e-05 - mse: 1.5417e-06 - val_loss: 4.8444e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00078: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00078: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 79/80\n",
      "375/375 [==============================] - 0s 609us/step - loss: 4.9947e-05 - mse: 1.5034e-06 - val_loss: 4.8449e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00079: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00079: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 80/80\n",
      "375/375 [==============================] - 0s 607us/step - loss: 4.9168e-05 - mse: 7.2338e-07 - val_loss: 4.8445e-05 - val_mse: 0.0000e+00\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_dummy_forward/losses.log\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00005\n",
      "\n",
      "Epoch 00080: saving model to model_dummy_forward/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00080: saving model to model_dummy_forward/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00080: saving model to model_dummy_forward/KERAS_check_model_epoch80.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    adam = Adam(lr=0.1)\n",
    "    model.compile(optimizer=adam, loss=['mse'], metrics=['mse'])\n",
    "\n",
    "    # Get reference pretrained predictions \n",
    "    y_ref_pretrained = model.predict(np.ascontiguousarray(X_test))\n",
    "\n",
    "    # callbacks = all_callbacks(stop_patience = 1000,\n",
    "    #                           lr_factor = 0.5,\n",
    "    #                           lr_patience = 10,\n",
    "    #                           lr_epsilon = 0.000001,\n",
    "    #                           lr_cooldown = 2,\n",
    "    #                           lr_minimum = 0.0000001,\n",
    "    #                           outputDir = 'model_dummy_forward')\n",
    "    callbacks = all_callbacks(stop_patience = 10000000, outputDir = 'model_dummy_forward')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(X_train_val, y_train_val, batch_size=16,\n",
    "              epochs=80, validation_split=0.25, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
    "    model = strip_pruning(model)\n",
    "    model.save('model_dummy_forward/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model('model_dummy_forward/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "LayerName\n",
      "  fc1_input\n",
      "    Precision\n",
      "      result:        ap_fixed<16,6>\n",
      "  fc1\n",
      "    Precision\n",
      "      weight:        ap_fixed<6,1>\n",
      "      bias:          ap_fixed<6,1>\n",
      "    ReuseFactor:     1\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "#config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "#config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_dummy_forward/hls4ml_prj',\n",
    "                                                       part='xcu250-figd2104-2L-e')\n",
    "hls_model.compile()\n",
    "\n",
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.825657423585654e-05, 1.1997992453958632)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu0AAALgCAYAAAAgIEm5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABlsElEQVR4nO3dd3gU1eLG8XfTAyShJISAQYqIWCiCIlhARUERxYoCUkQQBAVzVVAvRVFBf1IUURREuEqzol4QhAhXvYIoTa8CSjPUEFpCCmk7vz/QkZgQsiHJmd39fp5nn+fs2Zmdd1mFN5Ozsy7LsiwBAAAAcKwA0wEAAAAAFI/SDgAAADgcpR0AAABwOEo7AAAA4HCUdgAAAMDhKO0AAACAw1HaAQAAAIcLMh2gJNxut/bu3auIiAi5XC7TcQAAAIAzZlmWjh07ptq1aysgoPhz6V5R2vfu3av4+HjTMQAAAIAyt2vXLp111lnFbuMVpT0iIkLSiRcUGRlpOA0AAABw5tLS0hQfH2933eJ4RWn/c0lMZGQkpR0AAAA+pSTLv/kgKgAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADudxaf/qq6/UpUsX1a5dWy6XSwsXLjztPitXrtTFF1+s0NBQnXPOOZo1a1YpogIAAAD+yePSnpGRoWbNmmnq1Kkl2n7Hjh3q3Lmzrr76am3YsEHDhg3T/fffr6VLl3ocFgAAAPBHQZ7ucMMNN+iGG24o8fbTpk1T/fr1NWHCBElSkyZN9M0332jSpEnq2LGjp4cHAAAA/E65r2lftWqVOnToUGCuY8eOWrVq1Sn3yc7OVlpaWoEbAAAA4K/KvbTv379fsbGxBeZiY2OVlpamrKysIvcZN26coqKi7Ft8fHx5xwQAAAAcy5FXj3niiSeUmppq33bt2mU6EgAAAGCMx2vaPVWrVi0lJycXmEtOTlZkZKTCw8OL3Cc0NFShoaHlHQ0AAADwCuV+pr1NmzZKTEwsMLds2TK1adOmvA8NAAAA+ASPS3t6ero2bNigDRs2SDpxSccNGzYoKSlJ0omlLb169bK3HzhwoLZv367HH39cmzdv1muvvab33ntPjzzySNm8AgAAAMDHeVzaf/jhB7Vo0UItWrSQJCUkJKhFixYaNWqUJGnfvn12gZek+vXra9GiRVq2bJmaNWumCRMmaMaMGVzuEQAAACghl2VZlukQp5OWlqaoqCilpqYqMjLSdBwAAADgjHnScR159RgAAAAAf6G0AwAAAA5HaQcAAAAcjtIOAAAAOBylHQAAAHA4SjsAAADgcJR2AAAAwOEo7QAAAIDDUdoBAAAAh6O0A0AJWHl5yk1ONh0DAOCnKO0AUAKbL7xIW9u1V9bPP5uOAgDwQ5R2ADiNjNXf/XUnP99cEACA36K0A8BpHJo+XZIUXLeuwps2NZwGAOCPKO0AUIzM779Xxn//KwUHq+7Mt0zHAQD4KUo7AJyCZVn6/d5ekqSqd9yukLPOMpwIAOCvKO0AcArJ48bZ4+j+/Q0mAQD4O0o7ABTBsiwd+dc79v3g2rUNpgEA+DtKOwAU4dgXy04MgoLUcNkXZsMAAPwepR0A/sbKz1fKK69IkqIH9FdIfLzhRAAAf0dpB4C/2ZPwD+Vs26aAKlVUvW9f03EAAKC0A8DJ3FlZOrZ0qSQpIDJCgRERhhMBAEBpB4ACjn70kT2u//77BpMAAPAXSjsA/MGdna1Db5749tPYJ59UUI0ahhMBAHACpR0A/nBk3jzlJScrKC5OVe/uZjoOAAA2SjsASMpLSdGB8S9IkqIfeEABISGGEwEA8BdKOwBI2tb5Jnsc1fUWg0kAACiM0g7A7+WnpsrKypIkRXTsqICwMMOJAAAoiNIOwO8dmvm2rNxchTZqpDqTJpqOAwBAIZR2AH4td88eHZ49W5IU/fBDcgXw1yIAwHmCTAcAAJO2XtvBHkd06FDMlgAAmMMpJQB+K2vDBntcvU8fuVwuc2EAACgGpR2A3zr0x7IYSao5/HGDSQAAKB6lHYBfytm1S8eWLZcknf3OvzjLDgBwNEo7AL908NVXpbw8Vb7iClW65BLTcQAAKBalHYDfSVuyVKmffCpJihk61HAaAABOj9IOwO/sGTbMHodfdKG5IAAAlBClHYBfyfr5Z3vMFykBALwFpR2AX0l5+WVJUmSXLoq84QbDaQAAKBlKOwC/kbF6tTK++loKDFTMkMGm4wAAUGKUdgB+wbIsJfXpK0mq3Lq1Qs4+23AiAABKjtIOwC8cmTfPHkc/NMRgEgAAPEdpB+DzLMtS6scLJUlBMTGq1KKF2UAAAHiI0g7A56V/+aWO//STXOHhqv/xR6bjAADgMUo7AJ9m5eVp9+ATy2Gq33uvgqKjDScCAMBzlHYAPm33w39942mNfvcZTAIAQOlR2gH4LCsvT+lffilJcoWGKjAqynAiAABKh9IOwGelLlxojxsu+8JcEAAAzhClHYBPcufkKGXqa5KkmsOHK7hmTcOJAAAoPUo7AJ+0+6GHlLdvn4Jq1lS1e+42HQcAgDNCaQfgc/IOHVLGf76SJIW3vFgBYWGGEwEAcGYo7QB8TlK/++1x7eeeM5gEAICyQWkH4FPy09KUu2+fJCmySxcFVKpkOBEAAGeO0g7ApxyeNUvu1FSFNGyo2uPHmY4DAECZoLQD8Bk5O3fq4GuvS5JiHnpIrsBAw4kAACgblHYAPmNbpxvsccT11xlMAgBA2aK0A/AJucnJ9rhajx5yBfDXGwDAd/CvGgCfcOiNN+xx7D+fMpgEAICyR2kH4PVydu/Rkfc/kCTVnT1bLpfLcCIAAMoWpR2A19tx661Sbq4qt22jyq0vNR0HAIAyR2kH4NWOJSbKfeyYJKlar16G0wAAUD4o7QC82oGXJtjjiPbtzQUBAKAcUdoBeK3jmzYpZ8cOSdLZc+caTgMAQPmhtAPwWikvvyJJirzxRlW6uIXhNAAAlB9KOwCvdPhf/1L6ypWSpOiHhpgNAwBAOaO0A/BKyc+Ps8eh9esbTAIAQPmjtAPwOhmrV9vjs999x2ASAAAqBqUdgFexLEspkyZLkqr16KFKrVqZDQQAQAWgtAPwKukrVypr40a5wsIUPfAB03EAAKgQlHYAXsPKz9fuQQ9KkqreeaeCYmIMJwIAoGJQ2gF4jT0J/7DH1Xt0N5gEAICKRWkH4BWsvDwdW7r0xJ2AAIXUq2c0DwAAFYnSDsArpH76mSTJFR6uRv9ZaTYMAAAVjNIOwPGsnBwdnDpVkhQzZDBr2QEAfofSDsDxku7rp9w9exRYo4aqdWctOwDA/1DaATha3pEjyvzhB0lScJ06CggPN5wIAICKR2kH4GhH58+3x2e/PdNgEgAAzKG0A3Cs/PR0HZ79L0lS3HPPKqByZcOJAAAwg9IOwLEOz56t/KNHFVK/vqJuucV0HAAAjKG0A3CknN9/18Epr0qSYh4aIldQkOFEAACYQ2kH4EjbOnayxxHXX28wCQAA5lHaAThOXkqKPa7WvTtn2QEAfo/SDsBxDr45XZIU1qypYkf+03AaAADMo7QDcJTsbdt05I/LPNYcNkwul8twIgAAzON3zgAcZXvnmyRJrpAQVW7TxnAaAACcgTPtABzj+C+/2OOYRx4xmAQAAGehtANwjEMz37bHNfr2MRcEAACHobQDcITjW35V2qJFkqT6H39kOA0AAM5CaQfgCLsGDZQsSxGdOimsSRPTcQAAcBRKOwDjDs+Zo7y9+yRJ0Q8OMpwGAADnobQDMC557LP2OOzccw0mAQDAmSjtAIzKWLPGHted9XYxWwIA4L8o7QCMsSxLKZNfliRVveduVb7sMsOJAABwJko7AGOOLV+urHXr5AoNVfRA1rIDAHAqlHYARlhut/Y89LAkKeLaaxQcW9NwIgAAnIvSDsCIlEmT7HH0kCEGkwAA4HyUdgAVzsrP17EvV0iSQurXV2iDBoYTAQDgbJR2ABUubdEi5WzbpoCoKNV7b4HpOAAAOB6lHUCFcmdlae/jwyVJNfr1U2BEhOFEAAA4H6UdQIX6vee99rh6zx4GkwAA4D0o7QAqjDs7W8d//lmSFHx2XQVUqmQ4EQAA3oHSDqDCHJk3zx7X//BDg0kAAPAulHYAFcKdkaFDb06XJNUa+4wCq1QxnAgAAO9BaQdQIX7ve5/yDx9W8Nl1VbVrV9NxAADwKpR2AOUuZ/duHf/xR0lSlavayRUcbDgRAADepVSlferUqapXr57CwsLUunVrrVmzptjtJ0+erMaNGys8PFzx8fF65JFHdPz48VIFBuB9Dk6ZYo9jH3/MYBIAALyTx6V9wYIFSkhI0OjRo7Vu3To1a9ZMHTt21IEDB4rcfu7cuRoxYoRGjx6tTZs26a233tKCBQv05JNPnnF4AM6Xd+iQ0pYtlyTVfmE8Z9kBACgFj0v7xIkT1b9/f/Xt21fnn3++pk2bpkqVKmnmzJlFbv/tt9/q8ssvV/fu3VWvXj1df/31uueee057dh6Abzj05nRZmZkKu+giRd58s+k4AAB4JY9Ke05OjtauXasOHTr89QQBAerQoYNWrVpV5D5t27bV2rVr7ZK+fft2LV68WDfeeOMpj5Odna20tLQCNwDeJ2vjRh2ePVuSFDN0qFwul+FEAAB4pyBPNj548KDy8/MVGxtbYD42NlabN28ucp/u3bvr4MGDuuKKK2RZlvLy8jRw4MBil8eMGzdOTz/9tCfRADjQzm532+PKl7c1mAQAAO9W7lePWblypZ5//nm99tprWrdunT766CMtWrRIY8eOPeU+TzzxhFJTU+3brl27yjsmgDKWs3OnPY5JSOAsOwAAZ8CjM+3R0dEKDAxUcnJygfnk5GTVqlWryH1Gjhype++9V/fff78k6aKLLlJGRoYGDBigp556SgEBhX9uCA0NVWhoqCfRADjMwddflyQFVKmi6AH9DacBAMC7eXSmPSQkRC1btlRiYqI953a7lZiYqDZt2hS5T2ZmZqFiHhgYKEmyLMvTvAC8QPbWrUr99DNJUt1Zs8yGAQDAB3h0pl2SEhIS1Lt3b7Vq1UqXXnqpJk+erIyMDPXt21eS1KtXL9WpU0fjxo2TJHXp0kUTJ05UixYt1Lp1a23dulUjR45Uly5d7PIOwLdsv6mLJCniug4Kv/ACw2kAAPB+Hpf2bt26KSUlRaNGjdL+/fvVvHlzLVmyxP5walJSUoEz6//85z/lcrn0z3/+U3v27FFMTIy6dOmi5557ruxeBQDHOPLee/a4et/7DCYBAMB3uCwvWKOSlpamqKgopaamKjIy0nQcAMXYcnFLuTMzJUlNNm8ynAYAAOfypOOW+9VjAPiPzHXr7MJe74MPDKcBAMB3UNoBlAnLspQyabIkqeqdd7KWHQCAMkRpB1AmUia/rMzvv5ckRT84yHAaAAB8C6UdwBmz3G4deuMN+35wXJzBNAAA+B5KO4Azduyk726o/8knBpMAAOCbKO0AzoiVn6+Dr0yRJNUYMEBhjc81nAgAAN9DaQdwRtIWf67s335TQESEavTjuuwAAJQHSjuAUnMfP669jz0mSarWs4cCo6IMJwIAwDdR2gGU2q4HBtrj6t27G0wCAIBvo7QDKBV3To5ytm+XJIWee66CYmIMJwIAwHdR2gGUytEF7ykvJUVBNWuq3nsLTMcBAMCnUdoBeCz/6FEdfPVVSSe+SCkgLMxwIgAAfBulHYDHtnXspPzUVElS1dtuM5wGAADfR2kH4JHcvXvtwl65bRu5QkIMJwIAwPdR2gF45PC7c+xx/LRpBpMAAOA/KO0ASizvyBEdnT9fklRn8mTOsgMAUEEo7QBK7ND0GXJnZir0/CaKuP4603EAAPAblHYAJZL1v591eOZMSVLNoUPlCuCvDwAAKgr/6gIokZ133GGPK191lcEkAAD4H0o7gNPK2b3HHkc/NEQul8tgGgAA/A+lHcBpHZw6VdKJSzzGDB5sOA0AAP6H0g6gWMc3bVLqJ59IkmKGDTMbBgAAPxVkOgAAZ9tx64lvPA2Oj1d406aG0wAA4J840w7glDJWrbLHMQ8/ZDAJAAD+jdIO4JQOz/6XPY7q0sVgEgAA/BulHUCRsjZsUPrKlVJgoBp8vth0HAAA/BqlHUCRkvrdL0mK6nqLQuvXN5wGAAD/RmkHUMiByZPlzsiQJEUPetBwGgAAQGkHUIBlWTo07Q37fshZdQymAQAAEqUdwN+kr1xpj+v/cX12AABgFqUdgM1yu5Xy8iuSpBr391NY43MNJwIAABKlHcBJkp99VtmbNyugShVV79fPdBwAAPAHSjsASZI7J0dH5s6TJAXVrKmgatUMJwIAAH+itAOQJO0fPcYe1317prkgAACgEEo7AFk5Ocpcs0aSFH7xxQqOjTWcCAAAnIzSDkBHPvhAuXv2KDAmWnXfmmE6DgAA+BtKO+Dn8o4cUfIzYyVJ0QMHKiA83HAiAADwd5R2wM9tv/lme1ztzjsNJgEAAKdCaQf8WH56uvJTDkqSwlu1lCskxHAiAABQFEo74McOz55tj+vO5IoxAAA4FaUd8FP5R4/q8NuzJEl1Jk5QAGfZAQBwLEo74Kd29uwpd3q6Qs87TxGdOpmOAwAAikFpB/zQ8U2blLN1myQpqksXuQL4qwAAACfjX2rAD6W8/Io9rn5fX4NJAABASVDaAT+Tu3evMv77X0nSWa9NlcvlMpwIAACcDqUd8DMpr70mKzdXlVq3VsQ115iOAwAASoDSDviR9P/8R6kffChJihk21HAaAABQUpR2wI/semCgPa7UooXBJAAAwBOUdsBPHN/yqz2Oe+45g0kAAICnKO2An0h55cQVYyI6dVLV228znAYAAHiC0g74gawff1R6YqIUEKCYhx8yHQcAAHiI0g74gZ13dZMkVbnmaoU2aGA4DQAA8BSlHfBxKVOn2uPqPXsaTAIAAEqL0g74MMuydHDKq/b9ypddZjANAAAoLUo74MMyvv76xCA4WA0WLzYbBgAAlBqlHfBRlmUpZfLLkk4siwltUN9wIgAAUFqUdsBH7Rs5Usd/+UUKDlaNAf1NxwEAAGeA0g74ICsnR6kffChJckkKqlbNbCAAAHBGKO2AD0r99yJ73HDpEoNJAABAWaC0Az7Gys3VwddflyTFJCQouHZtw4kAAMCZorQDPubohx8pd9cuBUZHq3rPHqbjAACAMkBpB3xIflqa9o8ZI0mK7n+/AipVMhsIAACUCUo74EN23n2PPY66/XaDSQAAQFmitAM+wp2RobxDhyRJldu2UWCVKoYTAQCAskJpB3zE4XfelTs1VcF16yr+jTdMxwEAAGWI0g74gNzkAzr45puSpJiHhsgVHGw4EQAAKEtBpgMAOHNb27Wzx5E33mgwCQAAKA+caQe8XG7yAXsc1bWrXIGBBtMAAIDyQGkHvNzhmW/Z47jnnzOYBAAAlBdKO+DFcvfv15F58yVJ8dOnyxXA/9IAAPgi/oUHvNjuwUNk5eQovFVLVb7ictNxAABAOaG0A14q/b//1fGff5Yk1bj/frlcLsOJAABAeaG0A15qV7/77XFE+/bmggAAgHJHaQe8UPbWrfa41pgx5oIAAIAKQWkHvFDKK1MkSRHXdVC1u7sZTgMAAMobpR3wMplr1+rYF19ILpdiHn7YdBwAAFABKO2Al/m9R09JUliTJgpt1MhwGgAAUBEo7YAXSf3sM3sck5BgMAkAAKhIlHbAS1iWpaPvvS9JcoWGqgrXZQcAwG9Q2gEvkfHtt8r8/nu5goPVcMnnpuMAAIAKRGkHvIDldmv3kIckSdW636PguDjDiQAAQEWitANeYN/IkbKysiRJNQYMMJwGAABUNEo74HCW263UDz+y7wfVqGEwDQAAMIHSDjhc2uK/1q83XL7cYBIAAGAKpR1wMCsvTwennPj205hhQxVyVh3DiQAAgAmUdsDB9jz2mHJ+/12B1aur+r33mo4DAAAMobQDDpWfnq5jny+RJIU2bKiAypUNJwIAAKZQ2gGHOjxrtj0+69UpBpMAAADTKO2AA7kzM3Vk/nxJUs3hwxUYFWU4EQAAMInSDjjQ4TlzlH/woILj41W9Zw/TcQAAgGGUdsBhcvfuVcqEiZKkmCGD5QoONpwIAACYRmkHHGbrNdfa48ibbjKYBAAAOAWlHXCQvCNH7HFk585yBQYaTAMAAJyC0g44yKHpM+xx7RdfMJgEAAA4CaUdcIjc5AM6MmeOJCn+jWmcZQcAADZKO+AQO26/XVZ2tsJbtFDlq64yHQcAADgIpR1wgIzv1ij/4EFJUtVud8nlchlOBAAAnITSDjjAgRdftMdVu3Y1FwQAADgSpR0wLHv7dh3ftEmSFD9jxmm2BgAA/ojSDhiWMmWK5HaryjXXqMoVl5uOAwAAHIjSDhh0dOFCHft8iSQpZujDhtMAAACnorQDBu0b8YQ9Dmvc2GASAADgZJR2wJCsDRvs8Vmvv2YuCAAAcDxKO2DIgckvS5Kibr9NEVdfbTgNAABwMko7YEDG6tXKXL1aCg5WzIMPmo4DAAAcrlSlferUqapXr57CwsLUunVrrVmzptjtjx49qsGDBysuLk6hoaE699xztXjx4lIFBrydZVlK6tNXkhTVubOC69QxnAgAADhdkKc7LFiwQAkJCZo2bZpat26tyZMnq2PHjtqyZYtq1qxZaPucnBxdd911qlmzpj744APVqVNHv//+u6pWrVoW+QGvc2D8C/a4eu9eBpMAAABv4XFpnzhxovr376++fU+cKZw2bZoWLVqkmTNnasSIEYW2nzlzpg4fPqxvv/1WwcHBkqR69eqdWWrAS1lutzJWr5YkucLCFNakieFEAADAG3i0PCYnJ0dr165Vhw4d/nqCgAB16NBBq1atKnKfTz/9VG3atNHgwYMVGxurCy+8UM8//7zy8/NPeZzs7GylpaUVuAG+4NjSpcreskUBVaronBVfmo4DAAC8hEel/eDBg8rPz1dsbGyB+djYWO3fv7/IfbZv364PPvhA+fn5Wrx4sUaOHKkJEybo2WefPeVxxo0bp6ioKPsWHx/vSUzAkdw5OUp+4UVJUvU+fRRUrZrhRAAAwFuU+9Vj3G63atasqTfffFMtW7ZUt27d9NRTT2natGmn3OeJJ55Qamqqfdu1a1d5xwTK3a77+yvvjx9uq/fpbTgNAADwJh6taY+OjlZgYKCSk5MLzCcnJ6tWrVpF7hMXF6fg4GAFBgbac02aNNH+/fuVk5OjkJCQQvuEhoYqNDTUk2iAo7kzMpT5x1WWAqtXV2CVKoYTAQAAb+LRmfaQkBC1bNlSiYmJ9pzb7VZiYqLatGlT5D6XX365tm7dKrfbbc/9+uuviouLK7KwA77o6Icf2eMGi/5tMAkAAPBGHi+PSUhI0PTp0zV79mxt2rRJgwYNUkZGhn01mV69eumJJ56wtx80aJAOHz6soUOH6tdff9WiRYv0/PPPa/DgwWX3KgAHc2dl6dD06ZKk2H/+k7XsAADAYx5f8rFbt25KSUnRqFGjtH//fjVv3lxLliyxP5yalJSkgIC/fhaIj4/X0qVL9cgjj6hp06aqU6eOhg4dquHDh5fdqwAc7MjcecpLSVFQ7ThVvetO03EAAIAXclmWZZkOcTppaWmKiopSamqqIiMjTccBSiw3OVlb27WXJNUa+4yq3UlpBwAAJ3jSccv96jGAP9vW6QZ7HHXLLQaTAAAAb0ZpB8pJ/tGjsrKzJUmRN96oAD54DQAASonSDpSTQ2+9JbndCm3cWLVf+j/TcQAAgBejtAPlIGf3bh3+1zuSpJihQ+UK4H81AABQeh5fPQbA6W3rcJ09rnJ1e2M5AACAb+D0H1DGcnbutMc1HnhALpfLXBgAAOATKO1AGTs4Y4Y9rvnIMHNBAACAz6C0A2UoZ+dOpX68UJJ09ry5ZsMAAACfQWkHylDS/f2l/HxVaddOlVq0MB0HAAD4CEo7UEZSP/u3cnfvliTVGPiA4TQAAMCXUNqBMrL3scfsMWfZAQBAWaK0A2Ug68cf7XHdt2caTAIAAHwRpR0oAymTX5YkRXXtqspt2hhOAwAAfA2lHThDh96aqYxvv5WCgxU9ZLDpOAAAwAdR2oEzYFmWDvzf/524k5urkLPOMhsIAAD4JEo7cAYOz55tj+u9/77BJAAAwJdR2oFSsixLaZ9+JkkKiotT+EUXGk4EAAB8FaUdKKVjXyzT8V9+UUClSqr/0Yem4wAAAB9GaQdKwcrN1Z6hQyVJ1fv0VlC1aoYTAQAAX0ZpB0ph16AH7XH1vn0NJgEAAP6A0g54yMrNVcY330iSAiIiFBgRYTgRAADwdZR2wENHP/zIHjdc8rnBJAAAwF9Q2gEPuLOzdfD11yVJsU8+qaAaNQwnAgAA/oDSDnhg9+AhyktOVlBcnKre3c10HAAA4Cco7UAJ5aWk2GvZK196qQJCQgwnAgAA/oLSDpTQwTen2+NaT48xFwQAAPgdSjtQAvmpqUpduFCSVGvsMwoICzMbCAAA+BVKO1ACh2a+LfexYwptdI6q3nab6TgAAMDPUNqB0zj+66869MYbkqTohx+WKzDQcCIAAOBvKO3Aaey4+RZ7HNGhg8EkAADAX1HagWLk7t9vj6v37i2Xy2UwDQAA8FeUdqAYB1+fJkkKb9VSNUcMN5wGAAD4K0o7cAo5SUk6+uGHkqSaw4Zxlh0AABgTZDoA4FTbru8oSQpt0kSVWrUynAYAAPgzzrQDRUhbssQeV7v7boNJAAAAKO1AkQ7830v2uFq3uwwmAQAAoLQDhWT972fl7tkjuVyqN3+e6TgAAACUduDvUl5+WZIU2eUmhTdvbjYMAACAKO1AAYdmzFDG119LkmKGDDGcBgAA4ARKO/AHy7J04KUJ9v2QunUNpgEAAPgLpR34Q8Z/v7XHZ8+bazAJAABAQZR2QCfOsqdMnixJqtbrXlVq0cJsIAAAgJNQ2gFJ6YmJOv6//8kVHq7oAQNMxwEAACiA0g6/Z+XlafeQhyRJ1bp1U1B0tOFEAAAABVHa4ff2Pj7cHlfr0d1gEgAAgKJR2uHXrLw8Zf38P0lS8FlnKSQ+3nAiAACAwijt8GupCxcq9/ckBVarpgafLDQdBwAAoEiUdvit/PQM+7rsNQYMUEDlyoYTAQAAFI3SDr+18447lH/0qCSp2j13mw0DAABQDEo7/JI7M1M5O3dKkkKbNFFAWJjZQHC835KP6cO1u5Wb7zYdBQDgh4JMBwBMODxnjj2uN+ddg0ngDR5e+KhWpC6VJNWI+Fztzz3LcCIAgL+htMPv5B87pkMz3pIkxY0fp4BKlQwngpM9Pb+fVmSvse+fF8d/LwCAikdph9/Z8+ijcqemKqRhQ0V16WI6DhzsotkXFZqrFVHdQBIAgL9jTTv8Svb27cr4z1eSpKp33iFXYKDhRHCqogr7T71/MpAEAABKO/zM9hs72+Pq995rMAmcjMIOAHAaSjv8Rm7yAXtcvXcvzrKjSBR2AIATUdrhNw69MU2SFN6ihWqOGGE4DZyIwg4AcCpKO/zC8V9/1ZH33pckxQwbJpfLZTgRnIbCDgBwMq4eA7+w4+ZbJEkBlSurcutLDaeB01DYAQBOx5l2+LysjRvtccwjjxhMAieisAMAvAGlHT7v0KxZ9rh6zx7mgsBxKOwAAG9BaYdPO75pk459vkRyuVT/k4Wm48BBKOwAAG9CaYdP2zXoQUlS5A03KKxxY8Np4BQUdgCAt6G0w2cdnj1befv3S5KiBz9oOA2cgsIOAPBGlHb4rORx4+1xaMOGBpPAKSjsAABvRWmHT8pYvdoe13v/PYNJ4BQUdgCAN6O0w+dYlqWUSZMlSdV69lT4RYXLGvwLhR0A4O0o7fA5KRMnKmvjRrnCwhT9wADTcWAYhR0A4Aso7fApVn6+Dk2fIUlyBQUpKCbGcCKYRGEHAPgKSjt8Suqnn9nj+h+8bzAJTKOwAwB8CaUdPsPKy9OhN9+UJNXof79C6tUzGwjGUNgBAL6G0g6fkfrpZ8rZsUOBVauqxgMPmI4DQyjsAABfRGmHT3BnZGjfk09KOnGWPbBKFcOJYAKFHQDgqyjt8Ak7777HHle96y6DSWAKhR0A4Mso7fB67qwsZf/2myQp5JyGCoyIMJwIFY3CDgDwdZR2eL0jc+fZ4/oLFhhMAhMo7AAAf0Bph1fLT0/XoenTJUlxzz2ngMqVDSdCRaKwAwD8BaUdXi2pdx/lHz2qkPr1FXXLzabjoAJR2AEA/oTSDq+V8/vvOv7zz5KkKtdcLVdQkOFEqCgUdgCAv6G0w2ulvPyyPa6ZkGAwCSoShR0A4I8o7fBKeSkpOvblCklS7f97Ua7AQMOJUBEo7AAAf0Vph1c6+Mabso4fV1izpoq86SbTcVABKOwAAH9GaYfXyVy7VkfefVeSVHPYMLlcLsOJUN4o7AAAf0dph9f5vUdPe1y5TRuDSVARKOwAAFDa4WVydu60xzWHDzcXBBWCwg4AwAmUdniVlCmvSpKqtGunGn37mA2DckVhBwDgL5R2eI3jW7YobfFiSVLMsKGG06A8UdgBACiIb6OB19hxS1dJUqVLLlFYkyZmw6DcUNgBACiMM+3wCkc/XmiPq/fuZS4IyhWFHQCAolHa4RXSPvvMHkd06GAwCcoLhR0AgFOjtMPxMtasUca330rBwWq4fJnpOCgHFHYAAIpHaYejWZal/c88I0mqesftCjnrLMOJUNYo7AAAnB6lHY6WPG6ccrZukyRFDxxkOA3KGoUdAICSobTDsSy3W0f+9Y59Pzi2psE0KGsUdgAASo7SDsc6tmy5PW6w6N8Gk6CsUdgBAPAMpR2OZOXnK2XKK5KkGoMGKrRhQ8OJUFYo7AAAeI7SDkdKW7RIOVu3KSAyUjX69jUdB2WEwg4AQOlQ2uE47qws7X18uCSpeq9eCoyMNJwIZYHCDgBA6VHa4ThJ9/Wzx9XuudtgEpQVCjsAAGeG0g5HcWdnKycpSZIUdsEFCqpRw3AinCkKOwAAZ47SDkc5On++8g8dUlBcnM6eN9d0HJwhCjsAAGWD0g7HyDtyRCmvvS5Jin5wkAJCQgwnwpmgsAMAUHaCTAcA/rT12g6yMjMlSVW7djUbBmeEwg4AQNniTDscIf/oUbuwV2nfXq7gYMOJUFoUdgAAyl6pSvvUqVNVr149hYWFqXXr1lqzZk2J9ps/f75cLpe6chYVf3Po7Vn2+KxXp5gLgjNCYQcAoHx4XNoXLFighIQEjR49WuvWrVOzZs3UsWNHHThwoNj9du7cqUcffVRXXnllqcPCN+UdOqTD77wj6URhdwWxassbUdgBACg/Hpf2iRMnqn///urbt6/OP/98TZs2TZUqVdLMmTNPuU9+fr569Oihp59+Wg0aNDijwPA9ux8cLCszU2EXXqgq115rOg5KgcIOAED58qi05+TkaO3aterQocNfTxAQoA4dOmjVqlWn3O+ZZ55RzZo11a9fv1Nuc7Ls7GylpaUVuME3ZW3YoKyNGyVJ1e/tKZfLZTgRPEVhBwCg/HlU2g8ePKj8/HzFxsYWmI+NjdX+/fuL3Oebb77RW2+9penTp5f4OOPGjVNUVJR9i4+P9yQmvMje4SPsceTNNxtMgtKgsAMAUDHK9eoxx44d07333qvp06crOjq6xPs98cQTSk1NtW+7du0qx5QwJScpSTl79kiSar/4AmfZvQyFHQCAiuPRJ/6io6MVGBio5OTkAvPJycmqVatWoe23bdumnTt3qkuXLvac2+0+ceCgIG3ZskUNGzYstF9oaKhCQ0M9iQYvlPLqq1JenipfcYWiOMvuVSjsAABULI/OtIeEhKhly5ZKTEy059xutxITE9WmTZtC25933nn66aeftGHDBvt288036+qrr9aGDRtY9uLH0pZ+obRPP5MkxQwdajgNSsqyLAo7AAAGeHxtvYSEBPXu3VutWrXSpZdeqsmTJysjI0N9+/aVJPXq1Ut16tTRuHHjFBYWpgsvvLDA/lWrVpWkQvPwL3tOKurhF/Hfgjew3G41fadZoXkKOwAA5c/j0t6tWzelpKRo1KhR2r9/v5o3b64lS5bYH05NSkpSQABftIpTS//qK3tcZ9JEg0lQUu78fDV7t3mheQo7AAAVw2VZlmU6xOmkpaUpKipKqampioyMNB0HZyip/wBlfP21JKnJ5k2G0+B0KOwAAJQPTzoup8RRoTLXrj1R2AMD1XDpEtNxcBoUdgAAnIHSjgpjWZaS+g+QJFW9/XaFnH224UQoDoUdAADnoLSjwhx46SVZmZmSpOhBAw2nQXEo7AAAOAulHRXCsiwdfmumfT84Ls5gGhSHwg4AgPNQ2lEh0k+6tn+Df39mMAmK43a7KewAADgQpR3lzsrPV8rLr0iSajzwgELPOcdwIhQlPz9PzbgOOwAAjkRpR7nb//Qzyv7tNwVERKjGfX1Nx0ERcnNz1PzdFoXmKewAADgDpR3lyp2draPvvSdJCj7rLAVGRRlOhL/Ly8vVxXNbFpqnsAMA4ByUdpSrowsW2OO6b75hMAmKkpObrRZzLi40T2EHAMBZKO0oN+6cHB2aNUuSFDNsmIJiYswGQgHZucfVcm6rQvMUdgAAnIfSjnJzdMF7ytu7T0E1a6p6n96m4+AkmdkZajX3kkLzFHYAAJyJ0o5ykXf4sJKfe06SFP3gIAWEhRlOhD9l5War9fzLCs1T2AEAcC5KO8rF9htutMdRt95qMAlOlp6TqUtZEgMAgNehtKPM5R87pvzUVElS5bZtFRAaajgRJCk1K1Vt5rUuNE9hBwDA+SjtKHOH354lSQpp2FDx0980GwaSpCMZh3TFe1cUmqewAwDgHSjtKFN5hw/r8J9XjHnoIbkCA80Ggg6nH9JVH7QvNE9hBwDAewSZDgDf8lvbyyVJARERirj+OsNpkJy2Tx0+vr7QPIUdAADvwpl2lJmsn/5nj6NuvlmuAP7zMmlf6h4KOwAAPoJWhTKTMmmSPY7951MGk2DX0d26fmGnQvMUdgAAvBOlHWUiZ/duZXz/vSTprNdfk8vlMpzIf20/kqQbP7mh0DyFHQAA70VpR5k4OPU1KTdXldu2UcTVV5uO47c2HfpVt3zaudA8hR0AAO/GB1Fxxo4lJir1448lSTHDhpkN48c2Hdisuz6/s9A8hR0AAO/HmXacsd2Dh9jj8KZNDSbxXxv3rqOwAwDgwyjtOCPHN22yx7X/70WDSfzXf3//Sj2X9S40T2EHAMB3UNpxRlJefkWSFHnjjYrq0sVwGv+TuG2ZBq4cXGiewg4AgG+htKPUsjZsUPrKlVJgoKIfGnLa7VG2vvjtcw37JqHQPIUdAADfQ2lHqe28+x5JUsR11ym0fn3DafzLJ1s+0T++fbzQPIUdAADfxNVjUCqHZsywx9V79jCYxP+88/NcvfjDuELzFHYAAHwXpR0esyxLx5Ytt+9XatXKYBr/8vqG6Xpt4yuF5insAAD4Nko7PJa+cqWyNm6UKyxM5yz7wnQcvzFx9Ut6e8vsQvMUdgAAfB+lHR6x8vO1f+xYSSeWxQTFxBhO5B+e/eYZLdj2fqF5CjsAAP6B0g6P7En4h/L27pMkVe/Xz3Aa//DI8qFavufLQvMUdgAA/AelHSVm5eXp2NKlJ+4EBCioWjWzgfxA/8/7afWBNYXmKewAAPgXSjtKLPXTz+zxOV8mGkziH3ov6qV1B9cXmqewAwDgfyjtKBErJ0cHp06VJNV87FEF16plOJFv6/xhZyWlJxWap7ADAOCfKO0okX3PPKPcPXsUGBOtat27m47j066a305Hsg8XmqewAwDgv/hGVJxW3pEjSv3gQ0lSxNXXKCA83HAi33XR7IsKFfb4iHgKOwAAfo7SjtPaeedd9jh2+OMGk/i2i2ZfVGiubkRdLb5tsYE0AADASSjtKFZ+erryjxyRJFVud5UCKlc2nMg3FVXYL6hxgRbdtshAGgAA4DSUdhTr8OzZcmdkKKR+fcX/8UFUlK2iCnvL2Jaaf9N8A2kAAIATUdpxSrn79+vQjLckSTEPDZEriM8tl7WiCvud596pWZ1mVXwYAADgWLQwnNLW9lfb44hOnQwm8U1FFfZbz7lVo9qMMpAGAAA4GaUdRcrdv98eV73rLrkC+KVMWSqqsPc6v5ceu+QxA2kAAIDTUdpRpD+XxUhSrafHmAvig4oq7A82e1CDmg8ykAYAAHgDSjsKyd27V0cXLJAk1X17plwul+FEvqOowv7s5c/qlnNuMZAGAAB4C9Y8oJBdg4fIys1VpdatVblNG9NxfEZRhf2Zts9Q2AEAwGlxph0FHFu5UtmbNkmSagzobziN7yiqsI+9fKy6ntO14sMAAACvQ2lHAfuGj7DHVS6/3GAS31FUYZ967VRdddZVBtIAAABvRGmH7fiWX5WfliZJOmva64bT+IaiCvucG+eoaUxTA2kAAIC3Yk07bCmvvCJZliI6dVJE+/am43i9ogr7Oze8Q2EHAAAeo7RDknRkwXtKT0yUXC7FPPyQ6Ther6jCPrvTbDWv2bziwwAAAK/H8hhIkvaPHn1iYFkKbdDAbBgvV1Rh/6TrJ2oQxZ8rAAAoHUo7lLF6tT2uO+ttg0m8X1GFfentS1W7Sm0DaQAAgK+gtPs5y7KU8soUSVLUbbep8mWXGU7kvYoq7MvuWKZalWsZSAMAAHwJa9r9XMbXXytr3Tq5QkMVM3So6Theq6jCvvi2xRR2AABQJjjT7scst1u7BjwgSarWvbuCY2saTuSdiirsX3f7WlXDqlZ8GAAA4JM40+7H9j4+3B5Xu7ubwSTei8IOAAAqAqXdT1n5+Ur797/t+yFnn20wjXcqqrB/1e0rCjsAAChzLI/xUycX9nO+TDSYxDsVVdi/ufsbRYVGGUgDAAB8HaXdD1m5uUp5daokKSYhQcG1uRyhJ4oq7Gt7rlVIYIiBNAAAwB+wPMYP7fnHo8rdtUuB0dGq3rOH6ThepajC/kPPHyjsAACgXFHa/Ux+WpqOffGFJCnsvPMUUKmS4UTe41SFPTQw1EAaAADgT1ge42cOzZxpj+tMmmgwiXcpqrCv67lOwYHBBtIAAAB/Q2n3I+6MDB19731JUs0RwxUYEWE4kXcoqrBv7LVRAS5+UQUAACoGrcOPHH7nXeUfPqzgunVVvQdr2UuiqMK+/t71FHYAAFChaB5+Imf3bqVMnixJinloiFzBLOs4nVMV9qAAfkEFAAAqFu3DT2zrcJ09jrzxRoNJvANLYgAAgJNQ2v1A3qFD9jiqa1e5AgMNpnG+ogr7j71+lMvlMpAGAACA5TF+4dCbb0qSwi68UHHjnjecxtko7AAAwIko7T4ud98+HZk3X5IUM3Qo5bMYFHYAAOBULI/xcVuvvkaSFBQXp8pXXG44jXNR2AEAgJNxpt2HZa5fb4+r3X03BfQUKOwAAMDpKO0+7Mi8efY4+oEBBpM4F4UdAAB4A0q7j8r+7TelffZvSVK99983nMaZKOwAAMBbUNp91P6xz0qWpYjrOij8ogtNx3EcCjsAAPAmfBDVBx15/31lrlkjSYp+6CHDaZynqML+U++fDCQBAAAoGc60+6D9I0fZ47BzzzWYxHko7AAAwBtR2n1M5rp19jh++nSDSZyHwg4AALwVpd2HWJallEmTJUlV77xTVa68wmwgB6GwAwAAb0Zp9yEZ336rzO+/lys4WNEPDjIdxzEo7AAAwNtR2n2E5XZrV7/7JUmRt9ys4Lg4w4mcgcIOAAB8AaXdRyQ/+5w9rn5vL4NJnIPCDgAAfAWl3QdYbrcyvz9xiceAypUV1pgrxlDYAQCAL6G0+4C0xZ8r+7etCoiI0DlfJpqOYxyFHQAA+BpKu5dzHz+uAy++KEmqcV9fBUZFGU5kFoUdAAD4Ikq7l0vq3Ud5Bw5Ikqr5+Vp2CjsAAPBVlHYv5s7JUdbGjZKkoLg4BVapbDiRORR2AADgyyjtXuzogvfscYOFHxtMYhaFHQAA+DpKu5dyZ2bq4BtvSJJqjRnjt2vZKewAAMAfUNq91N7hw5V/8KCC4+NV9fbbTMcxgsIOAAD8BaXdC+Xu3atjy5ZLkiI73yhXcLDhRBWPwg4AAPwJpd0L7T/p209jHnzQYBIzKOwAAMDfUNq9TN6RI8pcvVqSVPOxR+UKCTGcqGJR2AEAgD+itHuZQ9NnyJ2ZqdDzm6h6376m41QoCjsAAPBXlHYvkvW/n3V45kxJUs2hQ+UK8J+3j8IOAAD8mf+0Ph+w84477HHlq64ymKRiUdgBAIC/o7R7iext2+xx9JAhcrlcBtNUHAo7AAAApd1rHJrxlj2OGTLYYJKKQ2EHAAA4gdLuBbK3b1fqJ59Ikuq9t8BwmopBYQcAAPgLpd0L7Lq/v+R2q8o11yi8aVPTccodhR0AAKAgSrvDHf14oXL37pUkRQ8aaDhN+aOwAwAAFEZpd7h9Tzxhj8MvKlxofQmFHQAAoGiUdgfLXL/eHtedPdtgkvJHYQcAADg1SruDpUx+WZIUdfttqtz6UsNpyg+FHQAAoHiUdoc6+OZ0ZX73nRQcrJgHHzQdp9xQ2AEAAE6vVKV96tSpqlevnsLCwtS6dWutWbPmlNtOnz5dV155papVq6Zq1aqpQ4cOxW4PybIspUyceOJObq6C69QxG6icUNgBAABKxuPSvmDBAiUkJGj06NFat26dmjVrpo4dO+rAgQNFbr9y5Urdc889WrFihVatWqX4+Hhdf/312rNnzxmH91XHli+3x/U//shgkvJDYQcAACg5l2VZlic7tG7dWpdccoleffVVSZLb7VZ8fLweeughjRgx4rT75+fnq1q1anr11VfVq1evEh0zLS1NUVFRSk1NVWRkpCdxvY7ldmvHbbcre/NmVe/dS7EnXT3GV1DYAQAAPOu4Hp1pz8nJ0dq1a9WhQ4e/niAgQB06dNCqVatK9ByZmZnKzc1V9erVT7lNdna20tLSCtz8xbGlS5W9ebMCqlRRjYG+d112CjsAAIDnPCrtBw8eVH5+vmJjYwvMx8bGav/+/SV6juHDh6t27doFiv/fjRs3TlFRUfYtPj7ek5hey52Toz2PJEiSqvfpo6Bq1QwnKlsUdgAAgNKp0KvHjB8/XvPnz9fHH3+ssLCwU273xBNPKDU11b7t2rWrAlOas+v+/va46l13GkxS9ijsAAAApRfkycbR0dEKDAxUcnJygfnk5GTVqlWr2H1feukljR8/XsuXL1fTpk2L3TY0NFShoaGeRPN6Vk6OsjZskCQFxcYquGZNs4HKEIUdAADgzHh0pj0kJEQtW7ZUYmKiPed2u5WYmKg2bdqccr8XX3xRY8eO1ZIlS9SqVavSp/VhRz74QFZOjgJjotVwyeem45QZCjsAAMCZ8+hMuyQlJCSod+/eatWqlS699FJNnjxZGRkZ6tu3rySpV69eqlOnjsaNGydJeuGFFzRq1CjNnTtX9erVs9e+V6lSRVWqVCnDl+K93JmZOvT6NElS9MCBCggPN5yobFDYAQAAyobHpb1bt25KSUnRqFGjtH//fjVv3lxLliyxP5yalJSkgIC/TuC//vrrysnJ0R133FHgeUaPHq0xY8acWXofsbVjR+WnHJQkVbvTN9ayU9gBAADKjsfXaTfBl6/Tnpt8QFvbtZMkVWrVSme/+47hRGeOwg4AAHB65XaddpS9g9Net8fxM98ymKRsUNgBAADKHqXdoPyjR5X22b8lSXHPPaeAkBDDic4MhR0AAKB8UNoNOvTWW3Knpyv0vPMUdWtX03HOCIUdAACg/FDaDTm+aZMOTZ8hSYp5+GG5Arz3raCwAwAAlC/vbYpebsett9njKle3N5bjTFHYAQAAyh+l3YDcvXvtcY0BA+RyuQymKT0KOwAAQMWgtBuQ8tprkqRKrVurZsIjhtOUDoUdAACg4lDaK1j2jh1K/XihJClm2FCzYUqJwg4AAFCxPP5GVJyZ7TfcKEkKa9pUlVq0MJzGcxR2AACAiseZ9gp0bOVKe1zt7rvNBSklCjsAAIAZlPYKdPT9D+xx1dtuNZjEcxR2AAAAcyjtFSTrxx+VnpgoBQSoweJFpuN4hMIOAABgFqW9guwbPUaSFHXzzQpt0MBsGA9Q2AEAAMyjtFeAlNdeU/amTZKk6CGDDacpOQo7AACAM1Day5llWTr4yhT7fshZZxlMU3IUdgAAAOegtJezjK+/tsf13n/fYJKSo7ADAAA4C6W9HFmWpZTJL0uSqvfpo/CLLjSc6PQo7AAAAM5DaS9HB6e8quO//KKASpVUY0B/03FOi8IOAADgTJT2cmLl5urga69JkkLPO09B1asbTlQ8CjsAAIBzUdrLyZ6EBHtc5/9eNJjk9CjsAAAAzkZpLwdWbq6Ob9osSQo5+2wF16ljONGpUdgBACgf7du317Bhw4wdv0+fPuratatj8uDMBJkO4IuOfvSxcnfvVmB0tOp//JHpOKdEYQcAwH989NFHCg4ONh0DpURpL2P5x44pZeJESVL0gAEKqFTJcKKiUdgBAPAv1R3++ToUj+UxZWzHLV2Vn5oqSap6dzfDaYpGYQcAeCvLspSZk2fkZlmWx3nz8vI0ZMgQRUVFKTo6WiNHjrSf55133lGrVq0UERGhWrVqqXv37jpw4IC975EjR9SjRw/FxMQoPDxcjRo10ttvv20/vmvXLt11112qWrWqqlevrltuuUU7d+48ZZa/L4+pV6+enn/+ed13332KiIhQ3bp19eabbxbYx9NjoPxwpr0MuTMylLt3ryQpvFkzBYSEGE5UGIUdAODNsnLzdf6opUaO/cszHVUpxLPqNHv2bPXr109r1qzRDz/8oAEDBqhu3brq37+/cnNzNXbsWDVu3FgHDhxQQkKC+vTpo8WLF0uSRo4cqV9++UWff/65oqOjtXXrVmVlZUmScnNz1bFjR7Vp00Zff/21goKC9Oyzz6pTp0768ccfFVLCDjJhwgSNHTtWTz75pD744AMNGjRI7dq1U+PGjcvsGCgblPYydPidd+1x3dmzzAU5BQo7AAAVKz4+XpMmTZLL5VLjxo31008/adKkSerfv7/uu+8+e7sGDRrolVde0SWXXKL09HRVqVJFSUlJatGihVq1aiXpxJnxPy1YsEBut1szZsyQy+WSJL399tuqWrWqVq5cqeuvv75E+W688UY9+OCDkqThw4dr0qRJWrFihRo3blxmx0DZoLSXkfzUVB166y1JUu3/+z8FhIUZTlQQhR0A4AvCgwP1yzMdjR3bU5dddpldeCWpTZs2mjBhgvLz87VhwwaNGTNGGzdu1JEjR+R2uyVJSUlJOv/88zVo0CDdfvvtWrduna6//np17dpVbdu2lSRt3LhRW7duVURERIHjHT9+XNu2bStxvqZNm9pjl8ulWrVq2Ut0yuoYKBuU9jKy5x+Pyn3smEIbNVJk5xtNxymAwg4A8BUul8vjJSpOdPz4cXXs2FEdO3bUnDlzFBMTo6SkJHXs2FE5OTmSpBtuuEG///67Fi9erGXLlunaa6/V4MGD9dJLLyk9PV0tW7bUnDlzCj13TExMiXP8/WoyLpfL/uGhrI6BsuH9/9U7wPFff1XGN99Ikqrec7dcAc75fC+FHQAAc7777rsC91evXq1GjRpp8+bNOnTokMaPH6/4+HhJ0g8//FBo/5iYGPXu3Vu9e/fWlVdeqccee0wvvfSSLr74Yi1YsEA1a9ZUZGRkuWSviGOg5JzTLr3Y/tFj7HG1u+82F+RvKOwAAJiVlJSkhIQEbdmyRfPmzdOUKVM0dOhQ1a1bVyEhIZoyZYq2b9+uTz/9VGPHji2w76hRo/TJJ59o69at+vnnn/Xvf/9bTZo0kST16NFD0dHRuuWWW/T1119rx44dWrlypR5++GHt3r27TLJXxDFQcpT2M5Sze7eO//yzJKnW2Gccc5adwg4AgHm9evVSVlaWLr30Ug0ePFhDhw7VgAEDFBMTo1mzZun999/X+eefr/Hjx+ull14qsG9ISIieeOIJNW3aVFdddZUCAwM1f/58SVKlSpX01VdfqW7durrtttvUpEkT9evXT8ePHy+zs+IVcQyUnMsqzUVHK1haWpqioqKUmprquP9Idg8dpmNLlyooNlbnrFxR4MMmplDYAQAAnM+TjuuM08JeKv2//9WxpSeuFVtnwksUdgAAAJQLSvsZ2NXvfntc6Y9rqJpEYQcAAPBNlPZSSlvy17ex1Xr6aYNJJMvtprADAAD4MEp7Ke0ZNsweV+t2l7EclmWp6TvNCs1T2AEAAHwHpb0Usv73sz2uM2misRxut1tN/9W00DyFHQAAwLdQ2kth5x13SJIib7pJkTfcYCSDOz9fzTjDDgAA4Bco7R5KmTrVHle97VYjGdz5+Wr2bvNC8xR2AAAA30Rp94BlWTo45VX7fuW2bSs8A4UdAADA/1DaPXDgpG8qO2vqq8VsWT4o7AAAAP6J0l5Cltutw2/NtO9HXHtthR6fwg4AAMrTzp075XK5tGHDBtNRypTL5dLChQvL7flXrlwpl8ulo0ePltsxJEp7iW076QOn9T/5pEKPTWEHAAAo3pgxY9S8efNC8/v27dMNhi4cUpaCTAfwBlZOjnJ/T7LvhzU+t8KO7Xa7KewAAPiBnJwchYSEmI7hc2rVqmU6QpngTHsJJD3wgD2u9+EHFXbcPC7rCABAkTJz8k55O56bX+bbeqp9+/YaMmSIhgwZoqioKEVHR2vkyJGyLMvepl69eho7dqx69eqlyMhIDRgwoMilFhs2bJDL5dLOnTslSbNmzVLVqlW1dOlSNWnSRFWqVFGnTp20b9++AhlmzJihJk2aKCwsTOedd55ee+21Ao+vWbNGLVq0UFhYmFq1aqX169d7/Dolafz48YqNjVVERIT69eunESNGFDjj3b59ew076UspJalr167q06ePff+dd95Rq1atFBERoVq1aql79+46cOCA/fiffy6JiYlq1aqVKlWqpLZt22rLli32n8nTTz+tjRs3yuVyyeVyadasWZIKLo8ZM2aM/fjJtz+3dbvdGjdunOrXr6/w8HA1a9ZMH3xQsPstXrxY5557rsLDw3X11Vfb70t540z7abizs5W5arV9P/yCCyrkuDm5OWo5t2WheQo7AADS+aOWnvKxqxvH6O2+l9r3W45drqy/lfM/ta5fXQseaGPfv+KFFTqckVNou53jO3uccfbs2erXr5/WrFmjH374QQMGDFDdunXVv39/e5uXXnpJo0aN0ujRoyVJu3btKtFzZ2Zm6qWXXtI777yjgIAA9ezZU48++qjmzJkjSZozZ45GjRqlV199VS1atND69evVv39/Va5cWb1791Z6erpuuukmXXfddXr33Xe1Y8cODR061OPX+N5772nMmDGaOnWqrrjiCr3zzjt65ZVX1KBBA4+eJzc3V2PHjlXjxo114MABJSQkqE+fPlq8eHGB7Z566ilNmDBBMTExGjhwoO677z7997//Vbdu3fS///1PS5Ys0fLlyyVJUVFRhY7z6KOPauDAgfb9P/+cWrVqJUkaN26c3n33XU2bNk2NGjXSV199pZ49eyomJkbt2rXTrl27dNttt2nw4MEaMGCAfvjhB/3jH//w9I+tVCjtp5HUp689bvT1VxVyzJzcbLWc26rQPIUdAADvER8fr0mTJsnlcqlx48b66aefNGnSpAKl/ZprrilQ+kpa2nNzczVt2jQ1bNhQkjRkyBA988wz9uOjR4/WhAkTdNttt0mS6tevr19++UVvvPGGevfurblz58rtduutt95SWFiYLrjgAu3evVuDBg3y6DVOnjxZ/fr1U79+/SRJzz77rJYvX67jx4979Dz33XefPW7QoIFeeeUVXXLJJUpPT1eVKlXsx5577jm1a9dOkjRixAh17txZx48fV3h4uKpUqaKgoKBil8NUqVLFfr7Vq1frn//8p2bPnq0LL7xQ2dnZev7557V8+XK1adPGzvLNN9/ojTfeULt27fT666+rYcOGmjBhgiTZ7+sLL7zg0estDUp7MfKOHFHWH78qCoqLU1BMTLkfMzc3h8IOAMBp/PJMx1M+FuByFbi/dmSHEm/7zfCrzyzYSS677DK5Tnr+Nm3aaMKECcrPz1dgYKAk2Wd4PVWpUiW7sEtSXFycvZwkIyND27ZtU79+/Qr8gJCXl2effd60aZOaNm2qsLCwAvk8tWnTpgJnrv98nhUrVnj0PGvXrtWYMWO0ceNGHTlyRG63W5KUlJSk888/396uadOm9jguLk6SdODAAdWtW9ej4yUlJalr16569NFHddddd0mStm7dqszMTF133XUFts3JyVGLFi0knXi9rVu3LvB4af7cSoPSXozf2vz15Un1K2Ate3bOcbWad0mheQo7AAAFVQopeYUpr23LQuXKlQvcDwg48XHDk9e+5+bmFtovODi4wH2Xy2Xvk56eLkmaPn16oYL55w8LFSkgIKDA65EKvqaMjAx17NhRHTt21Jw5cxQTE6OkpCR17NhROTkFlyqd/Lr//IHoz4JfUhkZGbr55pvVpk2bAr+d+PPPbdGiRapTp06BfUJDQz06Rnngg6inkHf4cIH7QdWrl+vxsrIzKewAAPiQ7777rsD91atXq1GjRsUW55g/fqt/8odKPb1uemxsrGrXrq3t27frnHPOKXCrX7++JKlJkyb68ccfCyxjWb169ame8pSaNGlS5Os8WUxMTIHXk5+fr//973/2/c2bN+vQoUMaP368rrzySp133nkFPoRaUiEhIcrPL/qzC3+yLEs9e/aU2+3WO++8U+A3Ieeff75CQ0OVlJRU6M8tPj7efr1r1qwp9vWWF0r7KSTd188eN16/rlyPlZ6drkvnty40T2EHAMB7JSUlKSEhQVu2bNG8efM0ZcqU037Y88+COGbMGP32229atGiRvX7aE08//bTGjRunV155Rb/++qt++uknvf3225o4caIkqXv37nK5XOrfv79++eUXLV68WC+d9M3vJTV06FDNnDlTb7/9tn799VeNHj1aP//8c4FtrrnmGi1atEiLFi3S5s2bNWjQoAJXx6lbt65CQkI0ZcoUbd++XZ9++qnGjh3rcZZ69eppx44d2rBhgw4ePKjs7OxC24wZM0bLly/XG2+8ofT0dO3fv1/79+9XVlaWIiIi9Oijj+qRRx7R7NmztW3bNq1bt05TpkzR7NmzJUkDBw7Ub7/9pscee0xbtmzR3Llz7SvPlDdKexHyU1OV+8dPhJFduiggPLzcjpWVm6028wuvhaKwAwDg3Xr16qWsrCxdeumlGjx4sIYOHaoBAwYUu09wcLDmzZunzZs3q2nTpnrhhRf07LPPenzs+++/XzNmzNDbb7+tiy66SO3atdOsWbPsM+1VqlTRZ599pp9++kktWrTQU089VeSHKevVq6cxY8ac8jjdunXTyJEj9fjjj6tly5b6/fffC32Y9b777lPv3r3Vq1cvtWvXTg0aNNDVV//12YGYmBjNmjVL77//vs4//3yNHz++VD9A3H777erUqZOuvvpqxcTEaN68eYW2+c9//qP09HS1bdtWcXFx9m3BggWSpLFjx2rkyJEaN26cmjRpok6dOmnRokX2n1vdunX14YcfauHChWrWrJmmTZum559/3uOspeGy/r7IyIHS0tIUFRWl1NRURUZGlvvxNp3XxB6f9/P/5Cqn9V/HstPVlsIOAIDPad++vZo3b67JkyebjlJqmZmZqlGjhj7//HO1b9++xPuNGTNGCxcu9HhZjz/ypONypv1vjm/51R5H3nhjuRX2g8cOUNgBAIBjrVixQtdcc41HhR3lh9L+NztuucUe1/6/F8vlGAeOJevqj64tNE9hBwAATtG5c2ctWrTIdAz8geUxJ8lNTtbWdu0lSdV69lStfz5V5sc4nH5Q7T4sfA1YCjsAAIB/YXlMKSWPG2+PY596ssyff+/R3RR2AAAAeIzS/oeM79bo2JIlkqT4GTMKXLezLPyaslkdP7mh0DyFHQAAAKdDaf9DUu/e9rjKFZeX6XNvTtms2xffWWiewg4AAICSoLRLOpaYaI+jBw8u0+fecXSX7qSwAwAA4AxQ2iXtHjzEHsc8NKSYLT2zcf9G3fzJjYXmKewAAADwhN+X9qMfL7THZXmJx//s+FI9l/YsNE9hBwAAgKf8vrTve+IJexzVpUuZPOfK7Yka8tXQQvMUdgAA/Ef79u01bNiwUz7ucrm0cOHCCstTlNNlhHP4dWnf++Rf12GvOWJ4mTznd79/q4e+HlZonsIOAADOlGVZuuGGGxxR+FGx/Lq0p370kT2u0afPGT/fkl8X6f6VDxSap7ADAICyMHny5DK/LDW8g9+W9gOTJ9vjs99954yf74OfF+ixVSMKzAW6AinsAACUg8ycPGXm5OnkL3bPyXMrMydP2Xn5RW7rdv+1bW7+iW2P55Zs29Jyu916/PHHVb16ddWqVUtjxowpcrucnBwNGTJEcXFxCgsL09lnn61x48YV2GbDhg2aMGGCZs6cWWj/lStXyuVyaenSpWrRooXCw8N1zTXX6MCBA/r888/VpEkTRUZGqnv37srMzCz164E5flnaLcvSoWlv2PcrtWp1Rs+3cMsnevqHZwvNb+i14YyeFwAAFO38UUt1/qilOpyRY8+9+dU2nT9qqUZ/8nOBbVuOXa7zRy3VnqNZ9ty/Vv2u80ct1fAPfyyw7RUvrND5o5Zqa0q6PffB2t2lzjl79mxVrlxZ3333nV588UU988wzWrZsWaHtXnnlFX366ad67733tGXLFs2ZM0f16tWzH8/MzFT37t01depU1apV65THGzNmjF599VV9++232rVrl+666y5NnjxZc+fO1aJFi/TFF19oypQppX49MCfIdAATtl59jT2u//FHxWx5egt+Wahnvx9ZaJ4z7AAAoGnTpho9erQkqVGjRnr11VeVmJio6667rsB2SUlJatSoka644gq5XC6dffbZBR5/5JFH1LZtW91yyy3FHu/ZZ5/V5Zef+JLIfv366YknntC2bdvUoEEDSdIdd9yhFStWaPjwsvksHyqO35V2Kz9fefv32/fDmjQp9XPN2vCOJmwseJnImuE1lXhX4in2AAAAZeGXZzpKksKDA+25AVc11H1X1FdgQME132tHdpAkhQX9tW2vNmfrnkvjFfC39eHfDL+60LZ3tDyr1DmbNm1a4H5cXJwOHDhQaLs+ffrouuuuU+PGjdWpUyfddNNNuv766yVJn376qb788kutX7/eo+PFxsaqUqVKdmH/c27NmjWlfTkwyO+Wx+xJ+Ic9rjd/XqmfZ9w3zxcq7F3P6UphBwCgAlQKCVKlkKACH8oMCQpQpZAghZ5UuE/eNuCkMh8ceGLbsOCSbVtawcHBBe67XC653YXXyF988cXasWOHxo4dq6ysLN1111264447JElffvmltm3bpqpVqyooKEhBQSfOud5+++1q3779KY/ncrlKfHw4n1+dabfy8nRs6dITdwICFN68eameZ+J/X9DcbQUL/5V1rtTYy8eeYUIAAOCvIiMj1a1bN3Xr1k133HGHOnXqpMOHD2vEiBG6//77C2x70UUXadKkSepSRt8xA+fzq9Ke/PyJT2G7wsJ0zrIvSvUcT6/8pz74/ZMCc5fUukSvdXjtjPMBAAD/NHHiRMXFxalFixYKCAjQ+++/r1q1aqlq1aoKCAgo8sOndevWVf369Q2khQl+U9rdGRk6MneuJKnyFZcrKCbG4+cYu3JUocJ+x7l3aHSb0WWSEQAA+KeIiAi9+OKL+u233xQYGKhLLrlEixcvVkCA361kxim4rJMvcOpQaWlpioqKUmpqqiIjI0v1HFuvuVa5e/dKkhqt+lZB1ap5tP/IL5/Qwl3/LjA34tIR6tGkR6nyAAAAwL950nH94se3vCNH7MIeWL26x4X92a+fL1TYBzUbRGEHAABAhfCL5TFH5v31oVFP17Lf9ek92nTkfwXmHmj6gB5s/mCZZAMAAABOx+dLe25ysg6+cuKbv+Kee1YBlSuXeN8RK54qVNgfa/WYel3Qq0wzAgAAAMXx+dK+9doO9jjqNN8idrJhS4cqcf+XBeZeveZVtYtvV2bZAAAAgJLw6dKevWOHlJcnSYq4roNcQSV7ucM+H6zEA18VmJt67VRdddZVZZ4RAAAAOB2fLu3bb7jRHteZOLFE+1w0+6JCc+OuHEdhBwAAgDE+W9qPb9pkj6veeadcf/sa36L0+qR7obmXr35Z19S9pkyzAQAAAJ7w2dK+49bb7HGtZ54+7fY9Ft6tH1N/LjA3r/M8XRh9YZlnAwAAADzhk9dpT/3sr2uqV73rLrlcrmK3bze/faHC/sktn1DYAQCA39m5c6dcLpc2bNhQ4n3GjBmj5s2bl1sm+Og3om46r4k9brJ5UzFbFr2Gfc6Nc9Q0pqnnQQEAAAxwuVz6+OOP1bVr1zN+rvz8fKWkpCg6OlpBJbyIR3p6urKzs1WjRo0zPr4/8aTj+tzymPT//MceV7v33mK3vfTd1oXmPrr5IzWq1qjMcwEAABQnJydHISEhxp8/MDBQtWrV8ui5q1SpoipVqpQ2GkrA55bH7HpgoD2u9dSTp9yu2exmysrPLDC36NZFFHYAAFAm2rdvryFDhmjIkCGKiopSdHS0Ro4cqT8XOdSrV09jx45Vr169FBkZqQEDBkiSvvnmG1155ZUKDw9XfHy8Hn74YWVkZJzyOPXq1ZMk3XrrrXK5XPb9P5eszJgxQ/Xr11dYWJgkacmSJbriiitUtWpV1ahRQzfddJO2bdtmP9/fl8esXLlSLpdLiYmJatWqlSpVqqS2bdtqy5Yt9j5/Xx7Tp08fde3aVS+99JLi4uJUo0YNDR48WLm5ufY2+/btU+fOnRUeHq769etr7ty5qlevniZPnlzaP3Kf5lOl/cDLL9vjuOefP+V2F82+SG65C8wtv2O56kbWLbdsAACg7GTm5Hl8y8v/69/+vHy3MnPydDw3v0TPW1qzZ89WUFCQ1qxZo5dfflkTJ07UjBkz7MdfeuklNWvWTOvXr9fIkSO1bds2derUSbfffrt+/PFHLViwQN98842GDBlyymN8//33kqS3335b+/bts+9L0tatW/Xhhx/qo48+skt4RkaGEhIS9MMPPygxMVEBAQG69dZb5Xa7i3p621NPPaUJEybohx9+UFBQkO67775it1+xYoW2bdumFStWaPbs2Zo1a5ZmzZplP96rVy/t3btXK1eu1Icffqg333xTBw4cKPY5/ZlPLY859Po0e1z1tluL3KaoNeyJdyaqZqWa5ZYLAACUrfNHLfV4n6ndL1bnpnGSpKU/J2vw3HVqXb+6FjzQxt7mihdW6HBGTqF9d47vXKqc8fHxmjRpklwulxo3bqyffvpJkyZNUv/+/SVJ11xzjf7xj3/Y299///3q0aOHhg0bJklq1KiRXnnlFbVr106vv/66fbb8ZDExMZKkqlWrFlrWkpOTo3/961/2NpJ0++23F9hm5syZiomJ0S+//KILLzz1RTiee+45tWt34pvhR4wYoc6dO+v48eNFZpKkatWq6dVXX1VgYKDOO+88de7cWYmJierfv782b96s5cuX6/vvv1erVq0kSTNmzFCjRqx4OBWfOdN++N059jjmkUeK3IbCDgAAKtJll11W4Cp2bdq00W+//ab8/BNn+P8srH/auHGjZs2aZa8Rr1Klijp27Ci3260dO3bo+eefL/BYUlJSscc/++yzCxR2Sfrtt990zz33qEGDBoqMjLSX05zuuZo2/esiHXFxJ374Ke7M+AUXXKDAwMAC+/y5/ZYtWxQUFKSLL77Yfvycc85RtWrVis3gz3zmTHvys8/a4+gHBhR6vKjC/s3d3ygqNKpccwEAgLL3yzMdPd4nJPCvc5UdL4jVL890VMDfLgv9zfCrzzibJypXrlzgfnp6uh544AE9/PDDhbatW7euBg4cqLvuusueq127tkfPL0ldunTR2WefrenTp6t27dpyu9268MILlZNT+DcMJws+6Ysq//xBpLglNcF/+2JLl8t12iU4ODWfKO0Za9bY47qz3i70eFGFfdU9q1QlhE85AwDgjSqFnFmFCQoMUFBg4QUHZ/q8f/fdd98VuL969Wo1atSowBnok1188cX65ZdfdM455xT5ePXq1VW9evVC88HBwfbZ++IcOnRIW7Zs0fTp03XllVdKOvHB14rWuHFj5eXlaf369WrZsqWkE+vvjxw5UuFZvIXXL4+xLEspk098ALXq3d1U+bLLCjxeVGH/vsf3FHYAAFDukpKSlJCQoC1btmjevHmaMmWKhg4desrthw8frm+//VZDhgzRhg0b9Ntvv+mTTz4p9oOo0okryCQmJmr//v3FFt9q1aqpRo0aevPNN7V161Z9+eWXSkhIKPXrK63zzjtPHTp00IABA7RmzRqtX79eAwYMUHh4+Gm/FNNfeX1pP7Z8ubLWrZMrNFTRgwYVeKyowr66+2qFBRX9gQkAAICy1KtXL2VlZenSSy/V4MGDNXToUPvSjkVp2rSp/vOf/+jXX3/VlVdeqRYtWmjUqFGnXQYzYcIELVu2TPHx8WrRosUptwsICND8+fO1du1aXXjhhXrkkUf0f//3f6V+fWfiX//6l2JjY3XVVVfp1ltvVf/+/RUREXHKD7b6O6/+RlTL7dbm8y+QJEXeeKPqTJxgP3aqM+wUdgAAUBHat2+v5s2bc93xEtq9e7fi4+O1fPlyXXvttabjVAi/+UbUlIkT7XH0kMH2uKjC/kPPHxQaGFohuQAAAFC8L7/8Uunp6brooou0b98+Pf7446pXr56uuuoq09EcyWtLu5Wfr2MrVkqSQurVU2iDBpKkm+ZdX2jbdfeuU3BAcKF5AAAAmJGbm6snn3xS27dvV0REhNq2bas5c+YUuuoMTvDa5TGpn3yivcNHKCAqSucsX6bAiAjOsAMAAMBr+PzyGHdWlvaOeEKSVKNfv1MW9vX3rldQgFe+RAAAAMDmlY32yNy50h+/IKjes4cuefeSQttsuHeDAgOKvgYqAAAA4E28rrS7s7N1+F/vSJJi/pGgu5c9oOP5xwts82OvH7nGJwAAAHyG112n/ci8ecpLTlZQrVqaUHuLNh3dUODxjb02UtgBAADgU7zqTHvewYM6MP4FSdLnbcP074NLCzzOGXYAAAD4Iq8607791tvs8cxzdhV4jMIOAAAAX+VVpd3KzJQkrT3HpfzAvwo6hR0AAAC+zKtKuyQlRUsv3v5XbAo7AAAAfJ3XlfYFVwXICjhR0insAAAA8Ade9UHUY+HS9+eeKOk/9f7JcBoAAACgYnhFabf++CKl5Y3cyj/u1qp7ViktLc1wKgAAAKD0/uyzf3bd4riskmxl2O7duxUfH286BgAAAFDmdu3apbPOOqvYbbyitLvdbu3du1cRERGsYfcBaWlpio+P165duxQZGWk6Ds4Q76fv4T31LbyfvoX307dYlqVjx46pdu3aCggo/qOmXrE8JiAg4LQ/fcD7REZG8heOD+H99D28p76F99O38H76jqioqBJt53VXjwEAAAD8DaUdAAAAcDhKOypcaGioRo8erdDQUNNRUAZ4P30P76lv4f30Lbyf/ssrPogKAAAA+DPOtAMAAAAOR2kHAAAAHI7SDgAAADgcpR0AAABwOEo7AAAA4HCUdpSLqVOnql69egoLC1Pr1q21Zs2aU247ffp0XXnllapWrZqqVaumDh06FLs9Kp4n7+fJ5s+fL5fLpa5du5ZvQHjE0/fz6NGjGjx4sOLi4hQaGqpzzz1XixcvrqC0KAlP39PJkyercePGCg8PV3x8vB555BEdP368gtKiOF999ZW6dOmi2rVry+VyaeHChafdZ+XKlbr44osVGhqqc845R7NmzSr3nKh4lHaUuQULFighIUGjR4/WunXr1KxZM3Xs2FEHDhwocvuVK1fqnnvu0YoVK7Rq1SrFx8fr+uuv1549eyo4OYri6fv5p507d+rRRx/VlVdeWUFJURKevp85OTm67rrrtHPnTn3wwQfasmWLpk+frjp16lRwcpyKp+/p3LlzNWLECI0ePVqbNm3SW2+9pQULFujJJ5+s4OQoSkZGhpo1a6apU6eWaPsdO3aoc+fOuvrqq7VhwwYNGzZM999/v5YuXVrOSVHhLKCMXXrppdbgwYPt+/n5+Vbt2rWtcePGlWj/vLw8KyIiwpo9e3Z5RYQHSvN+5uXlWW3btrVmzJhh9e7d27rlllsqIClKwtP38/XXX7caNGhg5eTkVFREeMjT93Tw4MHWNddcU2AuISHBuvzyy8s1Jzwnyfr444+L3ebxxx+3LrjgggJz3bp1szp27FiOyWACZ9pRpnJycrR27Vp16NDBngsICFCHDh20atWqEj1HZmamcnNzVb169fKKiRIq7fv5zDPPqGbNmurXr19FxEQJleb9/PTTT9WmTRsNHjxYsbGxuvDCC/X8888rPz+/omKjGKV5T9u2bau1a9faS2i2b9+uxYsX68Ybb6yQzChbq1atKvD+S1LHjh1L/G8uvEeQ6QDwLQcPHlR+fr5iY2MLzMfGxmrz5s0leo7hw4erdu3ahf4SQsUrzfv5zTff6K233tKGDRsqICE8UZr3c/v27fryyy/Vo0cPLV68WFu3btWDDz6o3NxcjR49uiJioxileU+7d++ugwcP6oorrpBlWcrLy9PAgQNZHuOl9u/fX+T7n5aWpqysLIWHhxtKhrLGmXY4yvjx4zV//nx9/PHHCgsLMx0HHjp27JjuvfdeTZ8+XdHR0abjoAy43W7VrFlTb775plq2bKlu3brpqaee0rRp00xHQymtXLlSzz//vF577TWtW7dOH330kRYtWqSxY8eajgagGJxpR5mKjo5WYGCgkpOTC8wnJyerVq1axe770ksvafz48Vq+fLmaNm1anjFRQp6+n9u2bdPOnTvVpUsXe87tdkuSgoKCtGXLFjVs2LB8Q+OUSvP/Z1xcnIKDgxUYGGjPNWnSRPv371dOTo5CQkLKNTOKV5r3dOTIkbr33nt1//33S5IuuugiZWRkaMCAAXrqqacUEMD5PG9Sq1atIt//yMhIzrL7GP7PRJkKCQlRy5YtlZiYaM+53W4lJiaqTZs2p9zvxRdf1NixY7VkyRK1atWqIqKiBDx9P8877zz99NNP2rBhg327+eab7asaxMfHV2R8/E1p/v+8/PLLtXXrVvuHL0n69ddfFRcXR2F3gNK8p5mZmYWK+Z8/lFmWVX5hUS7atGlT4P2XpGXLlhX7by68lOlPwsL3zJ8/3woNDbVmzZpl/fLLL9aAAQOsqlWrWvv377csy7Luvfdea8SIEfb248ePt0JCQqwPPvjA2rdvn307duyYqZeAk3j6fv4dV49xFk/fz6SkJCsiIsIaMmSItWXLFuvf//63VbNmTevZZ5819RLwN56+p6NHj7YiIiKsefPmWdu3b7e++OILq2HDhtZdd91l6iXgJMeOHbPWr19vrV+/3pJkTZw40Vq/fr31+++/W5ZlWSNGjLDuvfdee/vt27dblSpVsh577DFr06ZN1tSpU63AwEBryZIlpl4CygmlHeViypQpVt26da2QkBDr0ksvtVavXm0/1q5dO6t37972/bPPPtuSVOg2evToig+OInnyfv4dpd15PH0/v/32W6t169ZWaGio1aBBA+u5556z8vLyKjg1iuPJe5qbm2uNGTPGatiwoRUWFmbFx8dbDz74oHXkyJGKD45CVqxYUeS/iX++h71797batWtXaJ/mzZtbISEhVoMGDay33367wnOj/Lksi9+FAQAAAE7GmnYAAADA4SjtAAAAgMNR2gEAAACHo7QDAAAADkdpBwAAAByO0g4AAAA4HKUdAAAAcDhKOwAAAOBwlHYAAADA4SjtAAAAgMNR2gEAAACH+3+BCc/Wq27O9AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_ref = load_model('model_dummy_forward/KERAS_check_best_model.h5', custom_objects={\"QDense\": QDense})\n",
    "y_pred = model_ref.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "plt.plot(y_test, y_pred)\n",
    "#plt.gca().set_prop_cycle(None) # reset the colors\n",
    "plt.plot(y_test, y_qkeras, linestyle='--')\n",
    "#plt.gca().set_prop_cycle(None) # reset the colors\n",
    "plt.plot(y_test, y_hls, linestyle=':')\n",
    "#plt.gca().set_prop_cycle(None) # reset the colors\n",
    "plt.plot(y_test, y_ref_pretrained, linestyle='-.')\n",
    "\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--'),\n",
    "         Line2D([0], [0], ls=':'),\n",
    "         Line2D([0], [0], ls='-.')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['baseline', 'pruned, quantized', 'hls4ml', 'pre-training'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)\n",
    "\n",
    "\n",
    "xmax = 1.2*np.max([np.max(X_test), np.max(y_test),np.max(y_ref_pretrained),np.max(y_pred)])\n",
    "xmin = 0.8*np.min([np.min(X_test), np.min(y_test),np.min(y_ref_pretrained),np.min(y_pred)])\n",
    "\n",
    "ax.set_xlim(xmin,xmax)\n",
    "ax.set_ylim(xmin,xmax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03517368, 0.01758684, 0.01758684],\n",
       "       [0.9503029 , 0.47515145, 0.47515145],\n",
       "       [0.30934059, 0.15467029, 0.1546703 ],\n",
       "       ...,\n",
       "       [0.07545041, 0.0377252 , 0.0377252 ],\n",
       "       [0.50679444, 0.25339722, 0.25339723],\n",
       "       [0.13754017, 0.06877009, 0.06877009]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((X_test,y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.48445025]], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "hls_model.build(reset=False, csim=False, synth=True, cosim=True, validation=False, export=False, vsynth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
