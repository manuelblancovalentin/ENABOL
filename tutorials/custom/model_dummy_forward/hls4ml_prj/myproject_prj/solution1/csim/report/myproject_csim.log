INFO: [SIM 2] *************** CSIM start ***************
INFO: [SIM 4] CSIM will launch GCC as the compiler.
   Compiling ../../../../myproject_test.cpp in debug mode
   Compiling ../../../../firmware/myproject.cpp in debug mode
   Generating csim.exe
Processing input 0
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.244141
cache2 (ground): 0.490027
divergences: 0.245886
grad: -0.245886
loss: 0.03023
Loss: 0.03023

---------------------------------
grads_in[0]=-0.245886
data_in[0]=0.980054
cache=-0.240982 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.25 --> 0.25241
biases[0]=0 --> 0.00245886
We are not actually using biases...
Inputs
0.980054 
Predictions
0.490027 
Quantized predictions
0.244141 
Loss
0.03023
Processing input 1
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.07227
cache2 (ground): 2.1252
divergences: 1.05294
grad: -1.05294
loss: 0.55434
Loss: 0.55434

---------------------------------
grads_in[0]=-1.05294
data_in[0]=4.25041
cache=-4.47542 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.25241 --> 0.297164
biases[0]=0 --> 0.0105294
We are not actually using biases...
Inputs
4.25041 
Predictions
2.1252 
Quantized predictions
1.07227 
Loss
0.55434
Processing input 2
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.65918
cache2 (ground): 2.79308
divergences: 1.1339
grad: -1.1339
loss: 0.642862
Loss: 0.642862

---------------------------------
grads_in[0]=-1.1339
data_in[0]=5.58615
cache=-6.33412 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.297164 --> 0.360505
biases[0]=0 --> 0.011339
We are not actually using biases...
Inputs
5.58615 
Predictions
2.79308 
Quantized predictions
1.65918 
Loss
0.642862
Processing input 3
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.430664
cache2 (ground): 0.598032
divergences: 0.167368
grad: -0.167368
loss: 0.0140059
Loss: 0.0140059

---------------------------------
grads_in[0]=-0.167368
data_in[0]=1.19606
cache=-0.200182 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.360505 --> 0.362507
biases[0]=0 --> 0.00167368
We are not actually using biases...
Inputs
1.19606 
Predictions
0.598032 
Quantized predictions
0.430664 
Loss
0.0140059
Processing input 4
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.500977
cache2 (ground): 0.691484
divergences: 0.190508
grad: -0.190508
loss: 0.0181466
Loss: 0.0181466

---------------------------------
grads_in[0]=-0.190508
data_in[0]=1.38297
cache=-0.263466 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.362507 --> 0.365142
biases[0]=0 --> 0.00190508
We are not actually using biases...
Inputs
1.38297 
Predictions
0.691484 
Quantized predictions
0.500977 
Loss
0.0181466
Processing input 5
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.713867
cache2 (ground): 0.978036
divergences: 0.264168
grad: -0.264168
loss: 0.0348925
Loss: 0.0348925

---------------------------------
grads_in[0]=-0.264168
data_in[0]=1.95607
cache=-0.516732 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.365142 --> 0.370309
biases[0]=0 --> 0.00264168
We are not actually using biases...
Inputs
1.95607 
Predictions
0.978036 
Quantized predictions
0.713867 
Loss
0.0348925
Processing input 6
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.957031
cache2 (ground): 1.29308
divergences: 0.336053
grad: -0.336053
loss: 0.0564658
Loss: 0.0564658

---------------------------------
grads_in[0]=-0.336053
data_in[0]=2.58617
cache=-0.869089 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.370309 --> 0.379
biases[0]=0 --> 0.00336053
We are not actually using biases...
Inputs
2.58617 
Predictions
1.29308 
Quantized predictions
0.957031 
Loss
0.0564658
Processing input 7
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.72754
cache2 (ground): 2.28017
divergences: 0.552626
grad: -0.552626
loss: 0.152698
Loss: 0.152698

---------------------------------
grads_in[0]=-0.552626
data_in[0]=4.56033
cache=-2.52016 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.379 --> 0.404202
biases[0]=0 --> 0.00552626
We are not actually using biases...
Inputs
4.56033 
Predictions
2.28017 
Quantized predictions
1.72754 
Loss
0.152698
Processing input 8
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.264648
cache2 (ground): 0.328033
divergences: 0.0633847
grad: -0.0633847
loss: 0.00200881
Loss: 0.00200881

---------------------------------
grads_in[0]=-0.0633847
data_in[0]=0.656066
cache=-0.0415845 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.404202 --> 0.404617
biases[0]=0 --> 0.000633847
We are not actually using biases...
Inputs
0.656066 
Predictions
0.328033 
Quantized predictions
0.264648 
Loss
0.00200881
Processing input 9
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.08887
cache2 (ground): 1.34656
divergences: 0.257697
grad: -0.257697
loss: 0.0332039
Loss: 0.0332039

---------------------------------
grads_in[0]=-0.257697
data_in[0]=2.69313
cache=-0.694011 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.404617 --> 0.411558
biases[0]=0 --> 0.00257697
We are not actually using biases...
Inputs
2.69313 
Predictions
1.34656 
Quantized predictions
1.08887 
Loss
0.0332039
Processing input 10
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.69043
cache2 (ground): 0.83996
divergences: 0.149531
grad: -0.149531
loss: 0.0111797
Loss: 0.0111797

---------------------------------
grads_in[0]=-0.149531
data_in[0]=1.67992
cache=-0.2512 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.411558 --> 0.41407
biases[0]=0 --> 0.00149531
We are not actually using biases...
Inputs
1.67992 
Predictions
0.83996 
Quantized predictions
0.69043 
Loss
0.0111797
Processing input 11
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.0107422
cache2 (ground): 0.0137653
divergences: 0.0030231
grad: -0.0030231
loss: 4.56956e-06
Loss: 4.56956e-06

---------------------------------
grads_in[0]=-0.0030231
data_in[0]=0.0275306
cache=-8.32276e-05 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.41407 --> 0.41407
biases[0]=0 --> 3.0231e-05
We are not actually using biases...
Inputs
0.0275306 
Predictions
0.0137653 
Quantized predictions
0.0107422 
Loss
4.56956e-06
Processing input 12
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.44531
cache2 (ground): 2.95343
divergences: 0.508119
grad: -0.508119
loss: 0.129092
Loss: 0.129092

---------------------------------
grads_in[0]=-0.508119
data_in[0]=5.90686
cache=-3.00139 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.41407 --> 0.444084
biases[0]=0 --> 0.00508119
We are not actually using biases...
Inputs
5.90686 
Predictions
2.95343 
Quantized predictions
2.44531 
Loss
0.129092
Processing input 13
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.0459
cache2 (ground): 3.43017
divergences: 0.384273
grad: -0.384273
loss: 0.073833
Loss: 0.073833

---------------------------------
grads_in[0]=-0.384273
data_in[0]=6.86034
cache=-2.63625 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.444084 --> 0.470447
biases[0]=0 --> 0.00384273
We are not actually using biases...
Inputs
6.86034 
Predictions
3.43017 
Quantized predictions
3.0459 
Loss
0.073833
Processing input 14
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.3584
cache2 (ground): 2.50728
divergences: 0.14888
grad: -0.14888
loss: 0.0110826
Loss: 0.0110826

---------------------------------
grads_in[0]=-0.14888
data_in[0]=5.01456
cache=-0.746567 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.470447 --> 0.477912
biases[0]=0 --> 0.0014888
We are not actually using biases...
Inputs
5.01456 
Predictions
2.50728 
Quantized predictions
2.3584 
Loss
0.0110826
Processing input 15
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.45898
cache2 (ground): 1.52737
divergences: 0.0683854
grad: -0.0683854
loss: 0.00233828
Loss: 0.00233828

---------------------------------
grads_in[0]=-0.0683854
data_in[0]=3.05474
cache=-0.208899 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.477912 --> 0.480001
biases[0]=0 --> 0.000683854
We are not actually using biases...
Inputs
3.05474 
Predictions
1.52737 
Quantized predictions
1.45898 
Loss
0.00233828
Processing input 16
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.93848
cache2 (ground): 2.01962
divergences: 0.081146
grad: -0.081146
loss: 0.00329234
Loss: 0.00329234

---------------------------------
grads_in[0]=-0.081146
data_in[0]=4.03925
cache=-0.327769 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.480001 --> 0.483279
biases[0]=0 --> 0.00081146
We are not actually using biases...
Inputs
4.03925 
Predictions
2.01962 
Quantized predictions
1.93848 
Loss
0.00329234
Processing input 17
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.36035
cache2 (ground): 2.44225
divergences: 0.0818956
grad: -0.0818956
loss: 0.00335344
Loss: 0.00335344

---------------------------------
grads_in[0]=-0.0818956
data_in[0]=4.88449
cache=-0.400019 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.483279 --> 0.487279
biases[0]=0 --> 0.000818956
We are not actually using biases...
Inputs
4.88449 
Predictions
2.44225 
Quantized predictions
2.36035 
Loss
0.00335344
Processing input 18
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.26953
cache2 (ground): 3.3558
divergences: 0.0862699
grad: -0.0862699
loss: 0.00372124
Loss: 0.00372124

---------------------------------
grads_in[0]=-0.0862699
data_in[0]=6.7116
cache=-0.579009 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.487279 --> 0.493069
biases[0]=0 --> 0.000862699
We are not actually using biases...
Inputs
6.7116 
Predictions
3.3558 
Quantized predictions
3.26953 
Loss
0.00372124
Processing input 19
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.0908203
cache2 (ground): 0.0923341
divergences: 0.00151382
grad: -0.00151382
loss: 1.14582e-06
Loss: 1.14582e-06

---------------------------------
grads_in[0]=-0.00151382
data_in[0]=0.184668
cache=-0.000279554 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.493069 --> 0.493072
biases[0]=0 --> 1.51382e-05
We are not actually using biases...
Inputs
0.184668 
Predictions
0.0923341 
Quantized predictions
0.0908203 
Loss
1.14582e-06
Processing input 20
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.52148
cache2 (ground): 2.55705
divergences: 0.0355637
grad: -0.0355637
loss: 0.000632389
Loss: 0.000632389

---------------------------------
grads_in[0]=-0.0355637
data_in[0]=5.1141
cache=-0.181876 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.493072 --> 0.494891
biases[0]=0 --> 0.000355637
We are not actually using biases...
Inputs
5.1141 
Predictions
2.55705 
Quantized predictions
2.52148 
Loss
0.000632389
Processing input 21
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.3125
cache2 (ground): 0.316035
divergences: 0.00353464
grad: -0.00353464
loss: 6.24686e-06
Loss: 6.24686e-06

---------------------------------
grads_in[0]=-0.00353464
data_in[0]=0.632069
cache=-0.00223414 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.494891 --> 0.494913
biases[0]=0 --> 3.53464e-05
We are not actually using biases...
Inputs
0.632069 
Predictions
0.316035 
Quantized predictions
0.3125 
Loss
6.24686e-06
Processing input 22
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.3457
cache2 (ground): 1.36044
divergences: 0.0147394
grad: -0.0147394
loss: 0.000108625
Loss: 0.000108625

---------------------------------
grads_in[0]=-0.0147394
data_in[0]=2.72089
cache=-0.0401042 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.494913 --> 0.495314
biases[0]=0 --> 0.000147394
We are not actually using biases...
Inputs
2.72089 
Predictions
1.36044 
Quantized predictions
1.3457 
Loss
0.000108625
Processing input 23
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.4541
cache2 (ground): 2.47743
divergences: 0.0233281
grad: -0.0233281
loss: 0.000272099
Loss: 0.000272099

---------------------------------
grads_in[0]=-0.0233281
data_in[0]=4.95486
cache=-0.115587 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.495314 --> 0.49647
biases[0]=0 --> 0.000233281
We are not actually using biases...
Inputs
4.95486 
Predictions
2.47743 
Quantized predictions
2.4541 
Loss
0.000272099
Processing input 24
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.938477
cache2 (ground): 0.94527
divergences: 0.00679386
grad: -0.00679386
loss: 2.30782e-05
Loss: 2.30782e-05

---------------------------------
grads_in[0]=-0.00679386
data_in[0]=1.89054
cache=-0.0128441 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.49647 --> 0.496599
biases[0]=0 --> 6.79386e-05
We are not actually using biases...
Inputs
1.89054 
Predictions
0.94527 
Quantized predictions
0.938477 
Loss
2.30782e-05
Processing input 25
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.826172
cache2 (ground): 0.831899
divergences: 0.00572705
grad: -0.00572705
loss: 1.63996e-05
Loss: 1.63996e-05

---------------------------------
grads_in[0]=-0.00572705
data_in[0]=1.6638
cache=-0.00952866 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.496599 --> 0.496694
biases[0]=0 --> 5.72705e-05
We are not actually using biases...
Inputs
1.6638 
Predictions
0.831899 
Quantized predictions
0.826172 
Loss
1.63996e-05
Processing input 26
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.7002
cache2 (ground): 1.71207
divergences: 0.0118732
grad: -0.0118732
loss: 7.0487e-05
Loss: 7.0487e-05

---------------------------------
grads_in[0]=-0.0118732
data_in[0]=3.42414
cache=-0.0406556 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.496694 --> 0.4971
biases[0]=0 --> 0.000118732
We are not actually using biases...
Inputs
3.42414 
Predictions
1.71207 
Quantized predictions
1.7002 
Loss
7.0487e-05
Processing input 27
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.40527
cache2 (ground): 2.41978
divergences: 0.0145109
grad: -0.0145109
loss: 0.000105283
Loss: 0.000105283

---------------------------------
grads_in[0]=-0.0145109
data_in[0]=4.83957
cache=-0.0702264 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.4971 --> 0.497803
biases[0]=0 --> 0.000145109
We are not actually using biases...
Inputs
4.83957 
Predictions
2.41978 
Quantized predictions
2.40527 
Loss
0.000105283
Processing input 28
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.21875
cache2 (ground): 2.22865
divergences: 0.00990033
grad: -0.00990033
loss: 4.90083e-05
Loss: 4.90083e-05

---------------------------------
grads_in[0]=-0.00990033
data_in[0]=4.4573
cache=-0.0441288 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.497803 --> 0.498244
biases[0]=0 --> 9.90033e-05
We are not actually using biases...
Inputs
4.4573 
Predictions
2.22865 
Quantized predictions
2.21875 
Loss
4.90083e-05
Processing input 29
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.98438
cache2 (ground): 2.99518
divergences: 0.0108066
grad: -0.0108066
loss: 5.83909e-05
Loss: 5.83909e-05

---------------------------------
grads_in[0]=-0.0108066
data_in[0]=5.99036
cache=-0.0647352 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.498244 --> 0.498891
biases[0]=0 --> 0.000108066
We are not actually using biases...
Inputs
5.99036 
Predictions
2.99518 
Quantized predictions
2.98438 
Loss
5.83909e-05
Processing input 30
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.44043
cache2 (ground): 2.44646
divergences: 0.00602555
grad: -0.00602555
loss: 1.81536e-05
Loss: 1.81536e-05

---------------------------------
grads_in[0]=-0.00602555
data_in[0]=4.89291
cache=-0.0294825 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.498891 --> 0.499186
biases[0]=0 --> 6.02555e-05
We are not actually using biases...
Inputs
4.89291 
Predictions
2.44646 
Quantized predictions
2.44043 
Loss
1.81536e-05
Processing input 31
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.9668
cache2 (ground): 2.97207
divergences: 0.0052774
grad: -0.0052774
loss: 1.39255e-05
Loss: 1.39255e-05

---------------------------------
grads_in[0]=-0.0052774
data_in[0]=5.94415
cache=-0.0313696 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499186 --> 0.4995
biases[0]=0 --> 5.2774e-05
We are not actually using biases...
Inputs
5.94415 
Predictions
2.97207 
Quantized predictions
2.9668 
Loss
1.39255e-05
Processing input 32
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.724609
cache2 (ground): 0.725787
divergences: 0.00117809
grad: -0.00117809
loss: 6.93943e-07
Loss: 6.93943e-07

---------------------------------
grads_in[0]=-0.00117809
data_in[0]=1.45157
cache=-0.00171008 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.4995 --> 0.499517
biases[0]=0 --> 1.17809e-05
We are not actually using biases...
Inputs
1.45157 
Predictions
0.725787 
Quantized predictions
0.724609 
Loss
6.93943e-07
Processing input 33
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.22559
cache2 (ground): 3.22962
divergences: 0.00403857
grad: -0.00403857
loss: 8.15503e-06
Loss: 8.15503e-06

---------------------------------
grads_in[0]=-0.00403857
data_in[0]=6.45925
cache=-0.0260861 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499517 --> 0.499778
biases[0]=0 --> 4.03857e-05
We are not actually using biases...
Inputs
6.45925 
Predictions
3.22962 
Quantized predictions
3.22559 
Loss
8.15503e-06
Processing input 34
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.33691
cache2 (ground): 1.33767
divergences: 0.000760555
grad: -0.000760555
loss: 2.89222e-07
Loss: 2.89222e-07

---------------------------------
grads_in[0]=-0.000760555
data_in[0]=2.67535
cache=-0.00203475 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499778 --> 0.499798
biases[0]=0 --> 7.60555e-06
We are not actually using biases...
Inputs
2.67535 
Predictions
1.33767 
Quantized predictions
1.33691 
Loss
2.89222e-07
Processing input 35
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.58008
cache2 (ground): 1.58082
divergences: 0.000745177
grad: -0.000745177
loss: 2.77645e-07
Loss: 2.77645e-07

---------------------------------
grads_in[0]=-0.000745177
data_in[0]=3.16165
cache=-0.00235599 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499798 --> 0.499822
biases[0]=0 --> 7.45177e-06
We are not actually using biases...
Inputs
3.16165 
Predictions
1.58082 
Quantized predictions
1.58008 
Loss
2.77645e-07
Processing input 36
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.69434
cache2 (ground): 2.69566
divergences: 0.00132465
grad: -0.00132465
loss: 8.77354e-07
Loss: 8.77354e-07

---------------------------------
grads_in[0]=-0.00132465
data_in[0]=5.39132
cache=-0.00714163 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499822 --> 0.499893
biases[0]=0 --> 1.32465e-05
We are not actually using biases...
Inputs
5.39132 
Predictions
2.69566 
Quantized predictions
2.69434 
Loss
8.77354e-07
Processing input 37
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.308594
cache2 (ground): 0.309321
divergences: 0.000727028
grad: -0.000727028
loss: 2.64285e-07
Loss: 2.64285e-07

---------------------------------
grads_in[0]=-0.000727028
data_in[0]=0.618642
cache=-0.00044977 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499893 --> 0.499898
biases[0]=0 --> 7.27028e-06
We are not actually using biases...
Inputs
0.618642 
Predictions
0.309321 
Quantized predictions
0.308594 
Loss
2.64285e-07
Processing input 38
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.37402
cache2 (ground): 1.37486
divergences: 0.000841022
grad: -0.000841022
loss: 3.53659e-07
Loss: 3.53659e-07

---------------------------------
grads_in[0]=-0.000841022
data_in[0]=2.74973
cache=-0.00231258 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499898 --> 0.499921
biases[0]=0 --> 8.41022e-06
We are not actually using biases...
Inputs
2.74973 
Predictions
1.37486 
Quantized predictions
1.37402 
Loss
3.53659e-07
Processing input 39
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.13379
cache2 (ground): 3.13458
divergences: 0.000788927
grad: -0.000788927
loss: 3.11203e-07
Loss: 3.11203e-07

---------------------------------
grads_in[0]=-0.000788927
data_in[0]=6.26916
cache=-0.00494591 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499921 --> 0.49997
biases[0]=0 --> 7.88927e-06
We are not actually using biases...
Inputs
6.26916 
Predictions
3.13458 
Quantized predictions
3.13379 
Loss
3.11203e-07
Processing input 40
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.99121
cache2 (ground): 1.99175
divergences: 0.000540257
grad: -0.000540257
loss: 1.45939e-07
Loss: 1.45939e-07

---------------------------------
grads_in[0]=-0.000540257
data_in[0]=3.9835
cache=-0.00215211 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.49997 --> 0.499992
biases[0]=0 --> 5.40257e-06
We are not actually using biases...
Inputs
3.9835 
Predictions
1.99175 
Quantized predictions
1.99121 
Loss
1.45939e-07
Processing input 41
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.40234
cache2 (ground): 2.40303
divergences: 0.000690222
grad: -0.000690222
loss: 2.38203e-07
Loss: 2.38203e-07

---------------------------------
grads_in[0]=-0.000690222
data_in[0]=4.80607
cache=-0.00331725 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.499992 --> 0.500025
biases[0]=0 --> 6.90222e-06
We are not actually using biases...
Inputs
4.80607 
Predictions
2.40303 
Quantized predictions
2.40234 
Loss
2.38203e-07
Processing input 42
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.2168
cache2 (ground): 3.21725
divergences: 0.000453711
grad: -0.000453711
loss: 1.02927e-07
Loss: 1.02927e-07

---------------------------------
grads_in[0]=-0.000453711
data_in[0]=6.4345
cache=-0.0029194 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500025 --> 0.500054
biases[0]=0 --> 4.53711e-06
We are not actually using biases...
Inputs
6.4345 
Predictions
3.21725 
Quantized predictions
3.2168 
Loss
1.02927e-07
Processing input 43
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.38574
cache2 (ground): 3.38578
divergences: 3.71933e-05
grad: -3.71933e-05
loss: 6.91671e-10
Loss: 6.91671e-10

---------------------------------
grads_in[0]=-3.71933e-05
data_in[0]=6.77156
cache=-0.000251857 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500054 --> 0.500057
biases[0]=0 --> 3.71933e-07
We are not actually using biases...
Inputs
6.77156 
Predictions
3.38578 
Quantized predictions
3.38574 
Loss
6.91671e-10
Processing input 44
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.89941
cache2 (ground): 1.89996
divergences: 0.000550628
grad: -0.000550628
loss: 1.51595e-07
Loss: 1.51595e-07

---------------------------------
grads_in[0]=-0.000550628
data_in[0]=3.79993
cache=-0.00209235 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500057 --> 0.500078
biases[0]=0 --> 5.50628e-06
We are not actually using biases...
Inputs
3.79993 
Predictions
1.89996 
Quantized predictions
1.89941 
Loss
1.51595e-07
Processing input 45
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.06641
cache2 (ground): 1.06658
divergences: 0.000178576
grad: -0.000178576
loss: 1.59446e-08
Loss: 1.59446e-08

---------------------------------
grads_in[0]=-0.000178576
data_in[0]=2.13317
cache=-0.000380932 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500078 --> 0.500081
biases[0]=0 --> 1.78576e-06
We are not actually using biases...
Inputs
2.13317 
Predictions
1.06658 
Quantized predictions
1.06641 
Loss
1.59446e-08
Processing input 46
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.52148
cache2 (ground): 1.52152
divergences: 3.8147e-05
grad: -3.8147e-05
loss: 7.27596e-10
Loss: 7.27596e-10

---------------------------------
grads_in[0]=-3.8147e-05
data_in[0]=3.04305
cache=-0.000116083 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500081 --> 0.500083
biases[0]=0 --> 3.8147e-07
We are not actually using biases...
Inputs
3.04305 
Predictions
1.52152 
Quantized predictions
1.52148 
Loss
7.27596e-10
Processing input 47
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.08008
cache2 (ground): 1.08004
divergences: -3.39746e-05
grad: 3.39746e-05
loss: 5.77138e-10
Loss: 5.77138e-10

---------------------------------
grads_in[0]=3.39746e-05
data_in[0]=2.16009
cache=7.33882e-05 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500083 --> 0.500082
biases[0]=0 --> -3.39746e-07
We are not actually using biases...
Inputs
2.16009 
Predictions
1.08004 
Quantized predictions
1.08008 
Loss
5.77138e-10
Processing input 48
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.834961
cache2 (ground): 0.83554
divergences: 0.000578821
grad: -0.000578821
loss: 1.67517e-07
Loss: 1.67517e-07

---------------------------------
grads_in[0]=-0.000578821
data_in[0]=1.67108
cache=-0.000967255 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500082 --> 0.500091
biases[0]=0 --> 5.78821e-06
We are not actually using biases...
Inputs
1.67108 
Predictions
0.83554 
Quantized predictions
0.834961 
Loss
1.67517e-07
Processing input 49
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.55664
cache2 (ground): 1.55711
divergences: 0.000468612
grad: -0.000468612
loss: 1.09798e-07
Loss: 1.09798e-07

---------------------------------
grads_in[0]=-0.000468612
data_in[0]=3.11422
cache=-0.00145936 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500091 --> 0.500106
biases[0]=0 --> 4.68612e-06
We are not actually using biases...
Inputs
3.11422 
Predictions
1.55711 
Quantized predictions
1.55664 
Loss
1.09798e-07
Processing input 50
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.82715
cache2 (ground): 2.8275
divergences: 0.000355959
grad: -0.000355959
loss: 6.33534e-08
Loss: 6.33534e-08

---------------------------------
grads_in[0]=-0.000355959
data_in[0]=5.65501
cache=-0.00201295 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500106 --> 0.500126
biases[0]=0 --> 3.55959e-06
We are not actually using biases...
Inputs
5.65501 
Predictions
2.8275 
Quantized predictions
2.82715 
Loss
6.33534e-08
Processing input 51
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.94727
cache2 (ground): 1.94745
divergences: 0.000185132
grad: -0.000185132
loss: 1.71369e-08
Loss: 1.71369e-08

---------------------------------
grads_in[0]=-0.000185132
data_in[0]=3.8949
cache=-0.000721071 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500126 --> 0.500133
biases[0]=0 --> 1.85132e-06
We are not actually using biases...
Inputs
3.8949 
Predictions
1.94745 
Quantized predictions
1.94727 
Loss
1.71369e-08
Processing input 52
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.42188
cache2 (ground): 3.42136
divergences: -0.0005126
grad: 0.0005126
loss: 1.31379e-07
Loss: 1.31379e-07

---------------------------------
grads_in[0]=0.0005126
data_in[0]=6.84272
cache=0.00350758 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500133 --> 0.500098
biases[0]=0 --> -5.126e-06
We are not actually using biases...
Inputs
6.84272 
Predictions
3.42136 
Quantized predictions
3.42188 
Loss
1.31379e-07
Processing input 53
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.6377
cache2 (ground): 1.63824
divergences: 0.000540137
grad: -0.000540137
loss: 1.45874e-07
Loss: 1.45874e-07

---------------------------------
grads_in[0]=-0.000540137
data_in[0]=3.27647
cache=-0.00176974 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500098 --> 0.500116
biases[0]=0 --> 5.40137e-06
We are not actually using biases...
Inputs
3.27647 
Predictions
1.63824 
Quantized predictions
1.6377 
Loss
1.45874e-07
Processing input 54
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.326172
cache2 (ground): 0.326323
divergences: 0.0001508
grad: -0.0001508
loss: 1.13703e-08
Loss: 1.13703e-08

---------------------------------
grads_in[0]=-0.0001508
data_in[0]=0.652645
cache=-9.84188e-05 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500116 --> 0.500117
biases[0]=0 --> 1.508e-06
We are not actually using biases...
Inputs
0.652645 
Predictions
0.326323 
Quantized predictions
0.326172 
Loss
1.13703e-08
Processing input 55
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.1123
cache2 (ground): 2.11261
divergences: 0.000305891
grad: -0.000305891
loss: 4.67847e-08
Loss: 4.67847e-08

---------------------------------
grads_in[0]=-0.000305891
data_in[0]=4.22522
cache=-0.00129246 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500117 --> 0.50013
biases[0]=0 --> 3.05891e-06
We are not actually using biases...
Inputs
4.22522 
Predictions
2.11261 
Quantized predictions
2.1123 
Loss
4.67847e-08
Processing input 56
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.17676
cache2 (ground): 2.17686
divergences: 9.799e-05
grad: -9.799e-05
loss: 4.80102e-09
Loss: 4.80102e-09

---------------------------------
grads_in[0]=-9.799e-05
data_in[0]=4.35371
cache=-0.00042662 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.50013 --> 0.500134
biases[0]=0 --> 9.799e-07
We are not actually using biases...
Inputs
4.35371 
Predictions
2.17686 
Quantized predictions
2.17676 
Loss
4.80102e-09
Processing input 57
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.191406
cache2 (ground): 0.191786
divergences: 0.000379652
grad: -0.000379652
loss: 7.20677e-08
Loss: 7.20677e-08

---------------------------------
grads_in[0]=-0.000379652
data_in[0]=0.383572
cache=-0.000145624 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500134 --> 0.500136
biases[0]=0 --> 3.79652e-06
We are not actually using biases...
Inputs
0.383572 
Predictions
0.191786 
Quantized predictions
0.191406 
Loss
7.20677e-08
Processing input 58
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.586914
cache2 (ground): 0.58712
divergences: 0.000206113
grad: -0.000206113
loss: 2.12413e-08
Loss: 2.12413e-08

---------------------------------
grads_in[0]=-0.000206113
data_in[0]=1.17424
cache=-0.000242026 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500136 --> 0.500138
biases[0]=0 --> 2.06113e-06
We are not actually using biases...
Inputs
1.17424 
Predictions
0.58712 
Quantized predictions
0.586914 
Loss
2.12413e-08
Processing input 59
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.172852
cache2 (ground): 0.173441
divergences: 0.000589624
grad: -0.000589624
loss: 1.73828e-07
Loss: 1.73828e-07

---------------------------------
grads_in[0]=-0.000589624
data_in[0]=0.346882
cache=-0.00020453 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500138 --> 0.50014
biases[0]=0 --> 5.89624e-06
We are not actually using biases...
Inputs
0.346882 
Predictions
0.173441 
Quantized predictions
0.172852 
Loss
1.73828e-07
Processing input 60
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.0830078
cache2 (ground): 0.0837575
divergences: 0.0007497
grad: -0.0007497
loss: 2.81025e-07
Loss: 2.81025e-07

---------------------------------
grads_in[0]=-0.0007497
data_in[0]=0.167515
cache=-0.000125586 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.50014 --> 0.500141
biases[0]=0 --> 7.497e-06
We are not actually using biases...
Inputs
0.167515 
Predictions
0.0837575 
Quantized predictions
0.0830078 
Loss
2.81025e-07
Processing input 61
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.12207
cache2 (ground): 2.12168
divergences: -0.000389576
grad: 0.000389576
loss: 7.58847e-08
Loss: 7.58847e-08

---------------------------------
grads_in[0]=0.000389576
data_in[0]=4.24336
cache=0.00165311 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500141 --> 0.500125
biases[0]=0 --> -3.89576e-06
We are not actually using biases...
Inputs
4.24336 
Predictions
2.12168 
Quantized predictions
2.12207 
Loss
7.58847e-08
Processing input 62
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.14258
cache2 (ground): 1.14265
divergences: 7.67708e-05
grad: -7.67708e-05
loss: 2.94688e-09
Loss: 2.94688e-09

---------------------------------
grads_in[0]=-7.67708e-05
data_in[0]=2.28531
cache=-0.000175445 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500125 --> 0.500127
biases[0]=0 --> 7.67708e-07
We are not actually using biases...
Inputs
2.28531 
Predictions
1.14265 
Quantized predictions
1.14258 
Loss
2.94688e-09
Processing input 63
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.54004
cache2 (ground): 2.54014
divergences: 0.000100136
grad: -0.000100136
loss: 5.01359e-09
Loss: 5.01359e-09

---------------------------------
grads_in[0]=-0.000100136
data_in[0]=5.08028
cache=-0.000508718 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500127 --> 0.500132
biases[0]=0 --> 1.00136e-06
We are not actually using biases...
Inputs
5.08028 
Predictions
2.54014 
Quantized predictions
2.54004 
Loss
5.01359e-09
Processing input 64
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.38477
cache2 (ground): 2.3844
divergences: -0.000368118
grad: 0.000368118
loss: 6.77555e-08
Loss: 6.77555e-08

---------------------------------
grads_in[0]=0.000368118
data_in[0]=4.7688
cache=0.00175548 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500132 --> 0.500114
biases[0]=0 --> -3.68118e-06
We are not actually using biases...
Inputs
4.7688 
Predictions
2.3844 
Quantized predictions
2.38477 
Loss
6.77555e-08
Processing input 65
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.36328
cache2 (ground): 2.3631
divergences: -0.000184298
grad: 0.000184298
loss: 1.69828e-08
Loss: 1.69828e-08

---------------------------------
grads_in[0]=0.000184298
data_in[0]=4.72619
cache=0.000871026 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500114 --> 0.500105
biases[0]=0 --> -1.84298e-06
We are not actually using biases...
Inputs
4.72619 
Predictions
2.3631 
Quantized predictions
2.36328 
Loss
1.69828e-08
Processing input 66
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.44434
cache2 (ground): 1.44486
divergences: 0.000523925
grad: -0.000523925
loss: 1.37249e-07
Loss: 1.37249e-07

---------------------------------
grads_in[0]=-0.000523925
data_in[0]=2.88972
cache=-0.001514 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500105 --> 0.500121
biases[0]=0 --> 5.23925e-06
We are not actually using biases...
Inputs
2.88972 
Predictions
1.44486 
Quantized predictions
1.44434 
Loss
1.37249e-07
Processing input 67
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.826172
cache2 (ground): 0.826895
divergences: 0.000722706
grad: -0.000722706
loss: 2.61152e-07
Loss: 2.61152e-07

---------------------------------
grads_in[0]=-0.000722706
data_in[0]=1.65379
cache=-0.0011952 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500121 --> 0.500133
biases[0]=0 --> 7.22706e-06
We are not actually using biases...
Inputs
1.65379 
Predictions
0.826895 
Quantized predictions
0.826172 
Loss
2.61152e-07
Processing input 68
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.34766
cache2 (ground): 1.34805
divergences: 0.000395536
grad: -0.000395536
loss: 7.82245e-08
Loss: 7.82245e-08

---------------------------------
grads_in[0]=-0.000395536
data_in[0]=2.6961
cache=-0.00106641 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500133 --> 0.500143
biases[0]=0 --> 3.95536e-06
We are not actually using biases...
Inputs
2.6961 
Predictions
1.34805 
Quantized predictions
1.34766 
Loss
7.82245e-08
Processing input 69
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.02734
cache2 (ground): 1.02781
divergences: 0.000469089
grad: -0.000469089
loss: 1.10022e-07
Loss: 1.10022e-07

---------------------------------
grads_in[0]=-0.000469089
data_in[0]=2.05563
cache=-0.00096427 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500143 --> 0.500153
biases[0]=0 --> 4.69089e-06
We are not actually using biases...
Inputs
2.05563 
Predictions
1.02781 
Quantized predictions
1.02734 
Loss
1.10022e-07
Processing input 70
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.0117188
cache2 (ground): 0.0121502
divergences: 0.000431458
grad: -0.000431458
loss: 9.30778e-08
Loss: 9.30778e-08

---------------------------------
grads_in[0]=-0.000431458
data_in[0]=0.0243004
cache=-1.04846e-05 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500153 --> 0.500153
biases[0]=0 --> 4.31458e-06
We are not actually using biases...
Inputs
0.0243004 
Predictions
0.0121502 
Quantized predictions
0.0117188 
Loss
9.30778e-08
Processing input 71
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.49707
cache2 (ground): 1.49723
divergences: 0.000158072
grad: -0.000158072
loss: 1.24933e-08
Loss: 1.24933e-08

---------------------------------
grads_in[0]=-0.000158072
data_in[0]=2.99446
cache=-0.000473338 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500153 --> 0.500158
biases[0]=0 --> 1.58072e-06
We are not actually using biases...
Inputs
2.99446 
Predictions
1.49723 
Quantized predictions
1.49707 
Loss
1.24933e-08
Processing input 72
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.30469
cache2 (ground): 2.30455
divergences: -0.000132799
grad: 0.000132799
loss: 8.81781e-09
Loss: 8.81781e-09

---------------------------------
grads_in[0]=0.000132799
data_in[0]=4.60911
cache=0.000612086 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500158 --> 0.500152
biases[0]=0 --> -1.32799e-06
We are not actually using biases...
Inputs
4.60911 
Predictions
2.30455 
Quantized predictions
2.30469 
Loss
8.81781e-09
Processing input 73
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.05078
cache2 (ground): 2.05087
divergences: 8.53539e-05
grad: -8.53539e-05
loss: 3.64264e-09
Loss: 3.64264e-09

---------------------------------
grads_in[0]=-8.53539e-05
data_in[0]=4.10173
cache=-0.000350099 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500152 --> 0.500155
biases[0]=0 --> 8.53539e-07
We are not actually using biases...
Inputs
4.10173 
Predictions
2.05087 
Quantized predictions
2.05078 
Loss
3.64264e-09
Processing input 74
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.00683594
cache2 (ground): 0.00726926
divergences: 0.000433327
grad: -0.000433327
loss: 9.3886e-08
Loss: 9.3886e-08

---------------------------------
grads_in[0]=-0.000433327
data_in[0]=0.0145385
cache=-6.29993e-06 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500155 --> 0.500155
biases[0]=0 --> 4.33327e-06
We are not actually using biases...
Inputs
0.0145385 
Predictions
0.00726926 
Quantized predictions
0.00683594 
Loss
9.3886e-08
Processing input 75
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.49609
cache2 (ground): 3.49581
divergences: -0.00028801
grad: 0.00028801
loss: 4.14748e-08
Loss: 4.14748e-08

---------------------------------
grads_in[0]=0.00028801
data_in[0]=6.99161
cache=0.00201365 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500155 --> 0.500135
biases[0]=0 --> -2.8801e-06
We are not actually using biases...
Inputs
6.99161 
Predictions
3.49581 
Quantized predictions
3.49609 
Loss
4.14748e-08
Processing input 76
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.61719
cache2 (ground): 1.61748
divergences: 0.000288248
grad: -0.000288248
loss: 4.15435e-08
Loss: 4.15435e-08

---------------------------------
grads_in[0]=-0.000288248
data_in[0]=3.23495
cache=-0.000932468 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500135 --> 0.500144
biases[0]=0 --> 2.88248e-06
We are not actually using biases...
Inputs
3.23495 
Predictions
1.61748 
Quantized predictions
1.61719 
Loss
4.15435e-08
Processing input 77
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.26074
cache2 (ground): 2.26056
divergences: -0.000182629
grad: 0.000182629
loss: 1.66766e-08
Loss: 1.66766e-08

---------------------------------
grads_in[0]=0.000182629
data_in[0]=4.52112
cache=0.000825686 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500144 --> 0.500136
biases[0]=0 --> -1.82629e-06
We are not actually using biases...
Inputs
4.52112 
Predictions
2.26056 
Quantized predictions
2.26074 
Loss
1.66766e-08
Processing input 78
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.73926
cache2 (ground): 1.73906
divergences: -0.000196576
grad: 0.000196576
loss: 1.93211e-08
Loss: 1.93211e-08

---------------------------------
grads_in[0]=0.000196576
data_in[0]=3.47812
cache=0.000683716 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500136 --> 0.500129
biases[0]=0 --> -1.96576e-06
We are not actually using biases...
Inputs
3.47812 
Predictions
1.73906 
Quantized predictions
1.73926 
Loss
1.93211e-08
Processing input 79
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.8623
cache2 (ground): 2.86212
divergences: -0.000181675
grad: 0.000181675
loss: 1.65029e-08
Loss: 1.65029e-08

---------------------------------
grads_in[0]=0.000181675
data_in[0]=5.72425
cache=0.00103995 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500129 --> 0.500119
biases[0]=0 --> -1.81675e-06
We are not actually using biases...
Inputs
5.72425 
Predictions
2.86212 
Quantized predictions
2.8623 
Loss
1.65029e-08
Processing input 80
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.43359
cache2 (ground): 2.43395
divergences: 0.000354052
grad: -0.000354052
loss: 6.26763e-08
Loss: 6.26763e-08

---------------------------------
grads_in[0]=-0.000354052
data_in[0]=4.8679
cache=-0.00172349 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500119 --> 0.500136
biases[0]=0 --> 3.54052e-06
We are not actually using biases...
Inputs
4.8679 
Predictions
2.43395 
Quantized predictions
2.43359 
Loss
6.26763e-08
Processing input 81
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.12598
cache2 (ground): 3.12564
divergences: -0.000340223
grad: 0.000340223
loss: 5.7876e-08
Loss: 5.7876e-08

---------------------------------
grads_in[0]=0.000340223
data_in[0]=6.25127
cache=0.00212683 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500136 --> 0.500115
biases[0]=0 --> -3.40223e-06
We are not actually using biases...
Inputs
6.25127 
Predictions
3.12564 
Quantized predictions
3.12598 
Loss
5.7876e-08
Processing input 82
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.26074
cache2 (ground): 3.26002
divergences: -0.000724316
grad: 0.000724316
loss: 2.62317e-07
Loss: 2.62317e-07

---------------------------------
grads_in[0]=0.000724316
data_in[0]=6.52004
cache=0.00472256 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500115 --> 0.500068
biases[0]=0 --> -7.24316e-06
We are not actually using biases...
Inputs
6.52004 
Predictions
3.26002 
Quantized predictions
3.26074 
Loss
2.62317e-07
Processing input 83
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.683594
cache2 (ground): 0.683793
divergences: 0.000199378
grad: -0.000199378
loss: 1.98757e-08
Loss: 1.98757e-08

---------------------------------
grads_in[0]=-0.000199378
data_in[0]=1.36759
cache=-0.000272666 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500068 --> 0.50007
biases[0]=0 --> 1.99378e-06
We are not actually using biases...
Inputs
1.36759 
Predictions
0.683793 
Quantized predictions
0.683594 
Loss
1.98757e-08
Processing input 84
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.33301
cache2 (ground): 1.33373
divergences: 0.000717282
grad: -0.000717282
loss: 2.57247e-07
Loss: 2.57247e-07

---------------------------------
grads_in[0]=-0.000717282
data_in[0]=2.66745
cache=-0.00191331 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.50007 --> 0.500089
biases[0]=0 --> 7.17282e-06
We are not actually using biases...
Inputs
2.66745 
Predictions
1.33373 
Quantized predictions
1.33301 
Loss
2.57247e-07
Processing input 85
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.34766
cache2 (ground): 3.34754
divergences: -0.000114441
grad: 0.000114441
loss: 6.54836e-09
Loss: 6.54836e-09

---------------------------------
grads_in[0]=0.000114441
data_in[0]=6.69508
cache=0.000766192 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500089 --> 0.500082
biases[0]=0 --> -1.14441e-06
We are not actually using biases...
Inputs
6.69508 
Predictions
3.34754 
Quantized predictions
3.34766 
Loss
6.54836e-09
Processing input 86
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.6377
cache2 (ground): 1.63828
divergences: 0.000582337
grad: -0.000582337
loss: 1.69558e-07
Loss: 1.69558e-07

---------------------------------
grads_in[0]=-0.000582337
data_in[0]=3.27656
cache=-0.00190806 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500082 --> 0.500101
biases[0]=0 --> 5.82337e-06
We are not actually using biases...
Inputs
3.27656 
Predictions
1.63828 
Quantized predictions
1.6377 
Loss
1.69558e-07
Processing input 87
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.220703
cache2 (ground): 0.220789
divergences: 8.62032e-05
grad: -8.62032e-05
loss: 3.7155e-09
Loss: 3.7155e-09

---------------------------------
grads_in[0]=-8.62032e-05
data_in[0]=0.441579
cache=-3.80655e-05 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500101 --> 0.500101
biases[0]=0 --> 8.62032e-07
We are not actually using biases...
Inputs
0.441579 
Predictions
0.220789 
Quantized predictions
0.220703 
Loss
3.7155e-09
Processing input 88
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.47168
cache2 (ground): 2.47133
divergences: -0.000352621
grad: 0.000352621
loss: 6.21708e-08
Loss: 6.21708e-08

---------------------------------
grads_in[0]=0.000352621
data_in[0]=4.94265
cache=0.00174288 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500101 --> 0.500084
biases[0]=0 --> -3.52621e-06
We are not actually using biases...
Inputs
4.94265 
Predictions
2.47133 
Quantized predictions
2.47168 
Loss
6.21708e-08
Processing input 89
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.39746
cache2 (ground): 1.39786
divergences: 0.000398278
grad: -0.000398278
loss: 7.93128e-08
Loss: 7.93128e-08

---------------------------------
grads_in[0]=-0.000398278
data_in[0]=2.79572
cache=-0.00111347 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500084 --> 0.500095
biases[0]=0 --> 3.98278e-06
We are not actually using biases...
Inputs
2.79572 
Predictions
1.39786 
Quantized predictions
1.39746 
Loss
7.93128e-08
Processing input 90
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 3.12402
cache2 (ground): 3.12413
divergences: 0.000111103
grad: -0.000111103
loss: 6.17194e-09
Loss: 6.17194e-09

---------------------------------
grads_in[0]=-0.000111103
data_in[0]=6.24827
cache=-0.000694202 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500095 --> 0.500102
biases[0]=0 --> 1.11103e-06
We are not actually using biases...
Inputs
6.24827 
Predictions
3.12413 
Quantized predictions
3.12402 
Loss
6.17194e-09
Processing input 91
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.6748
cache2 (ground): 1.67524
divergences: 0.00043118
grad: -0.00043118
loss: 9.29581e-08
Loss: 9.29581e-08

---------------------------------
grads_in[0]=-0.00043118
data_in[0]=3.35047
cache=-0.00144466 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500102 --> 0.500116
biases[0]=0 --> 4.3118e-06
We are not actually using biases...
Inputs
3.35047 
Predictions
1.67524 
Quantized predictions
1.6748 
Loss
9.29581e-08
Processing input 92
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.37793
cache2 (ground): 1.37767
divergences: -0.000262737
grad: 0.000262737
loss: 3.45154e-08
Loss: 3.45154e-08

---------------------------------
grads_in[0]=0.000262737
data_in[0]=2.75533
cache=0.000723929 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500116 --> 0.500109
biases[0]=0 --> -2.62737e-06
We are not actually using biases...
Inputs
2.75533 
Predictions
1.37767 
Quantized predictions
1.37793 
Loss
3.45154e-08
Processing input 93
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.786133
cache2 (ground): 0.786501
divergences: 0.000367761
grad: -0.000367761
loss: 6.7624e-08
Loss: 6.7624e-08

---------------------------------
grads_in[0]=-0.000367761
data_in[0]=1.573
cache=-0.000578488 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500109 --> 0.500115
biases[0]=0 --> 3.67761e-06
We are not actually using biases...
Inputs
1.573 
Predictions
0.786501 
Quantized predictions
0.786133 
Loss
6.7624e-08
Processing input 94
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.526367
cache2 (ground): 0.526257
divergences: -0.000110447
grad: 0.000110447
loss: 6.09931e-09
Loss: 6.09931e-09

---------------------------------
grads_in[0]=0.000110447
data_in[0]=1.05251
cache=0.000116247 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500115 --> 0.500114
biases[0]=0 --> -1.10447e-06
We are not actually using biases...
Inputs
1.05251 
Predictions
0.526257 
Quantized predictions
0.526367 
Loss
6.09931e-09
Processing input 95
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 0.196289
cache2 (ground): 0.196958
divergences: 0.000668883
grad: -0.000668883
loss: 2.23702e-07
Loss: 2.23702e-07

---------------------------------
grads_in[0]=-0.000668883
data_in[0]=0.393916
cache=-0.000263484 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500114 --> 0.500116
biases[0]=0 --> 6.68883e-06
We are not actually using biases...
Inputs
0.393916 
Predictions
0.196958 
Quantized predictions
0.196289 
Loss
2.23702e-07
Processing input 96
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.8252
cache2 (ground): 2.82489
divergences: -0.000309467
grad: 0.000309467
loss: 4.7885e-08
Loss: 4.7885e-08

---------------------------------
grads_in[0]=0.000309467
data_in[0]=5.64977
cache=0.00174842 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500116 --> 0.500099
biases[0]=0 --> -3.09467e-06
We are not actually using biases...
Inputs
5.64977 
Predictions
2.82489 
Quantized predictions
2.8252 
Loss
4.7885e-08
Processing input 97
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.57422
cache2 (ground): 2.57391
divergences: -0.000311136
grad: 0.000311136
loss: 4.84029e-08
Loss: 4.84029e-08

---------------------------------
grads_in[0]=0.000311136
data_in[0]=5.14782
cache=0.00160167 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500099 --> 0.500083
biases[0]=0 --> -3.11136e-06
We are not actually using biases...
Inputs
5.14782 
Predictions
2.57391 
Quantized predictions
2.57422 
Loss
4.84029e-08
Processing input 98
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 1.59082
cache2 (ground): 1.59096
divergences: 0.000141263
grad: -0.000141263
loss: 9.97762e-09
Loss: 9.97762e-09

---------------------------------
grads_in[0]=-0.000141263
data_in[0]=3.18192
cache=-0.000449488 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500083 --> 0.500087
biases[0]=0 --> 1.41263e-06
We are not actually using biases...
Inputs
3.18192 
Predictions
1.59096 
Quantized predictions
1.59082 
Loss
9.97762e-09
Processing input 99
Ground truth passed to nnet seems valid, computing loss
cache1 (preds): 2.88086
cache2 (ground): 2.88132
divergences: 0.000457287
grad: -0.000457287
loss: 1.04556e-07
Loss: 1.04556e-07

---------------------------------
grads_in[0]=-0.000457287
data_in[0]=5.76263
cache=-0.00263518 for ii=0 jj=0
learning_rate=0.01
weights[0]=0.500087 --> 0.500114
biases[0]=0 --> 4.57287e-06
We are not actually using biases...
Inputs
5.76263 
Predictions
2.88132 
Quantized predictions
2.88086 
Loss
1.04556e-07
INFO: Saved inference results to file: tb_data/csim_results.log
INFO: [SIM 1] CSim done with 0 errors.
INFO: [SIM 3] *************** CSIM finish ***************
